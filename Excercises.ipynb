{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "T3tA5_d4iPsl",
        "rR8TG7c2lJmP"
      ],
      "authorship_tag": "ABX9TyNHXAM8LQD4b/1ev9q6jlt/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "36a684a9ff1043188f27ebf1fe8c02ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d67865d2a22b48ed8dba7fb8dc9c227f",
              "IPY_MODEL_7b2ddf03740b4287939e05c1390d7907",
              "IPY_MODEL_aec4e8e1609e4f258e8a86cbbeb335fa"
            ],
            "layout": "IPY_MODEL_da0109c535b8479b95507e2037af5eec"
          }
        },
        "d67865d2a22b48ed8dba7fb8dc9c227f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9c5bbc2757d4134ae1e5c21ef9aa8d7",
            "placeholder": "​",
            "style": "IPY_MODEL_d5e8f4a2f8064268be11558d082a58cc",
            "value": "modules.json: 100%"
          }
        },
        "7b2ddf03740b4287939e05c1390d7907": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61a6dbccd2674b11a07eae4f56d59ca9",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6317b67c11e6413e90cf1fffad7d4742",
            "value": 349
          }
        },
        "aec4e8e1609e4f258e8a86cbbeb335fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d3184a9e20c410aabf6a3c3b6335213",
            "placeholder": "​",
            "style": "IPY_MODEL_81530a27b8ae4ce0a80308da3408f52a",
            "value": " 349/349 [00:00&lt;00:00, 17.7kB/s]"
          }
        },
        "da0109c535b8479b95507e2037af5eec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9c5bbc2757d4134ae1e5c21ef9aa8d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5e8f4a2f8064268be11558d082a58cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61a6dbccd2674b11a07eae4f56d59ca9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6317b67c11e6413e90cf1fffad7d4742": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0d3184a9e20c410aabf6a3c3b6335213": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81530a27b8ae4ce0a80308da3408f52a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dad4bd44dba34e5f9666807b8e0fcb30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d5c0e4b307f54904b54a92aae97843eb",
              "IPY_MODEL_1b463d89db3e4efa8819caaa73c7636a",
              "IPY_MODEL_de7d8e2c66e74b33a15ff43df15de2c9"
            ],
            "layout": "IPY_MODEL_65c8dd29150748958a838aaad4df0b8c"
          }
        },
        "d5c0e4b307f54904b54a92aae97843eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e41b76eebd4043fbb19365fcc37ad718",
            "placeholder": "​",
            "style": "IPY_MODEL_d2fc3cb5435446b9acfbd246b12a2921",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "1b463d89db3e4efa8819caaa73c7636a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29a62c55a62243d98eb7c0692ccaba33",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eea401248dc747dcb5d34169b04b0106",
            "value": 116
          }
        },
        "de7d8e2c66e74b33a15ff43df15de2c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db7cf0cfb22a4f2c9747cffe2f7d42a6",
            "placeholder": "​",
            "style": "IPY_MODEL_bf4ad211aa5143be833db8d2a89ded28",
            "value": " 116/116 [00:00&lt;00:00, 7.81kB/s]"
          }
        },
        "65c8dd29150748958a838aaad4df0b8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e41b76eebd4043fbb19365fcc37ad718": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2fc3cb5435446b9acfbd246b12a2921": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29a62c55a62243d98eb7c0692ccaba33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eea401248dc747dcb5d34169b04b0106": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db7cf0cfb22a4f2c9747cffe2f7d42a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf4ad211aa5143be833db8d2a89ded28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5ae21441709449a9d3bb8af7d98631b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec16c49f207f41659fad9bdeae772db4",
              "IPY_MODEL_3277b21396aa40da898b8d8b8f0f65a7",
              "IPY_MODEL_429394a63e3644cdbdce8bbd8eeed7b7"
            ],
            "layout": "IPY_MODEL_7af8c9379557460f84dc97ce184b0a95"
          }
        },
        "ec16c49f207f41659fad9bdeae772db4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d089d3c40a2c44cea1b01898defa63f3",
            "placeholder": "​",
            "style": "IPY_MODEL_7c5467ec5f984086a4ddc2326b4a7dd4",
            "value": "README.md: 100%"
          }
        },
        "3277b21396aa40da898b8d8b8f0f65a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bdfeaab921d465285e5ecff3a9da680",
            "max": 10659,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db5b1e9afd4143419515655e4570aece",
            "value": 10659
          }
        },
        "429394a63e3644cdbdce8bbd8eeed7b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1d7bef49a67463d81f0b513b744600d",
            "placeholder": "​",
            "style": "IPY_MODEL_a4b624a4361a4b87bba5700807051d27",
            "value": " 10.7k/10.7k [00:00&lt;00:00, 339kB/s]"
          }
        },
        "7af8c9379557460f84dc97ce184b0a95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d089d3c40a2c44cea1b01898defa63f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c5467ec5f984086a4ddc2326b4a7dd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bdfeaab921d465285e5ecff3a9da680": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db5b1e9afd4143419515655e4570aece": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a1d7bef49a67463d81f0b513b744600d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4b624a4361a4b87bba5700807051d27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc4838e614a743168e0bf75a4e591dcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e5cdc72421604a3081c2b836baa74cab",
              "IPY_MODEL_e638728a562a4e0283d7377dc94b7a1f",
              "IPY_MODEL_1e4aa2dc416d4ab0b0cc39b184d3bf94"
            ],
            "layout": "IPY_MODEL_f857da686fb44988b1f36052bea0d1a0"
          }
        },
        "e5cdc72421604a3081c2b836baa74cab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12ddd572e13b42e6afddf85d765765d6",
            "placeholder": "​",
            "style": "IPY_MODEL_3172a6e365864bd69529116912565bdb",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "e638728a562a4e0283d7377dc94b7a1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f73c9c23c4a34799933291f914981a6d",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_67bdea1bef8141cc98f9b8e3d564e21d",
            "value": 53
          }
        },
        "1e4aa2dc416d4ab0b0cc39b184d3bf94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47d160388ffb453497b37d2bb8585b6f",
            "placeholder": "​",
            "style": "IPY_MODEL_c54b38efb9eb4b6f80b8872761076ce5",
            "value": " 53.0/53.0 [00:00&lt;00:00, 3.11kB/s]"
          }
        },
        "f857da686fb44988b1f36052bea0d1a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12ddd572e13b42e6afddf85d765765d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3172a6e365864bd69529116912565bdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f73c9c23c4a34799933291f914981a6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67bdea1bef8141cc98f9b8e3d564e21d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "47d160388ffb453497b37d2bb8585b6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c54b38efb9eb4b6f80b8872761076ce5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01060978bae6443a8e0ab4b6a7919e84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d0e5e1bf13df4d56a152193fc9cfc5b1",
              "IPY_MODEL_2effcca1d14d4e4aba8067fc4be51c22",
              "IPY_MODEL_166e0a1839e74ecf96da83b91b41f6cc"
            ],
            "layout": "IPY_MODEL_3e89cfe0e6d246c0b753829f205f24bc"
          }
        },
        "d0e5e1bf13df4d56a152193fc9cfc5b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3b55714551b42a49799fdc411b9695c",
            "placeholder": "​",
            "style": "IPY_MODEL_f88f0dacb088450299f01d455cbf3f84",
            "value": "config.json: 100%"
          }
        },
        "2effcca1d14d4e4aba8067fc4be51c22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9236adc5dfbb481c8bb509d00ab8c583",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f0a0c3c672e241b5af79ee17c15fb670",
            "value": 612
          }
        },
        "166e0a1839e74ecf96da83b91b41f6cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99ba75fc30b24e23adc6d591768b77e0",
            "placeholder": "​",
            "style": "IPY_MODEL_4bc52c89b24c44959689705f3cae4bcb",
            "value": " 612/612 [00:00&lt;00:00, 11.7kB/s]"
          }
        },
        "3e89cfe0e6d246c0b753829f205f24bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3b55714551b42a49799fdc411b9695c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f88f0dacb088450299f01d455cbf3f84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9236adc5dfbb481c8bb509d00ab8c583": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0a0c3c672e241b5af79ee17c15fb670": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "99ba75fc30b24e23adc6d591768b77e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bc52c89b24c44959689705f3cae4bcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07f8511b70a641d6bc5516456e0aae73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a363b24baa194f27b576a1b296990568",
              "IPY_MODEL_6d4cf1278cff4a1dbd6c01536fa48449",
              "IPY_MODEL_629b12c7534649f1ad5facaeee3b0e35"
            ],
            "layout": "IPY_MODEL_c534d53be5ea4031b02c55f91ecbe482"
          }
        },
        "a363b24baa194f27b576a1b296990568": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7674459bbcc3481c85fec003cd1c2012",
            "placeholder": "​",
            "style": "IPY_MODEL_310a4b7a64374d50b25f36704d84c85b",
            "value": "model.safetensors: 100%"
          }
        },
        "6d4cf1278cff4a1dbd6c01536fa48449": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_837cd0c5e51146f9abf74e805e46c321",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5803bd7c21e34bedb573147f3a4ba03e",
            "value": 90868376
          }
        },
        "629b12c7534649f1ad5facaeee3b0e35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ccc3a2a92b14609b97a54590a49f52e",
            "placeholder": "​",
            "style": "IPY_MODEL_e372cad798684087a13f2099a8d961aa",
            "value": " 90.9M/90.9M [00:00&lt;00:00, 231MB/s]"
          }
        },
        "c534d53be5ea4031b02c55f91ecbe482": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7674459bbcc3481c85fec003cd1c2012": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "310a4b7a64374d50b25f36704d84c85b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "837cd0c5e51146f9abf74e805e46c321": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5803bd7c21e34bedb573147f3a4ba03e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ccc3a2a92b14609b97a54590a49f52e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e372cad798684087a13f2099a8d961aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7079d414b9448bca43811f8781db78a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_42944b7cccf54743a2c54f9f5b71eb9e",
              "IPY_MODEL_59cedf1233694473b1c86a00153beeac",
              "IPY_MODEL_aa3303ee1f5e437c92559868f14849bc"
            ],
            "layout": "IPY_MODEL_624b45ac25544fd0bf6dd0ef98eda520"
          }
        },
        "42944b7cccf54743a2c54f9f5b71eb9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93a1c39416cf49cda347118a0729ae23",
            "placeholder": "​",
            "style": "IPY_MODEL_b9793d5bd60441e0ab47834114754e7a",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "59cedf1233694473b1c86a00153beeac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33c027289ec1437c8e00c2282f682bea",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d50ea40c19f44ba1a9d6678320cc023c",
            "value": 350
          }
        },
        "aa3303ee1f5e437c92559868f14849bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47cf7475f9c94367b4c4839f9a0dccdf",
            "placeholder": "​",
            "style": "IPY_MODEL_27520c8a56cf4199b4d8003d015e67f7",
            "value": " 350/350 [00:00&lt;00:00, 5.78kB/s]"
          }
        },
        "624b45ac25544fd0bf6dd0ef98eda520": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93a1c39416cf49cda347118a0729ae23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9793d5bd60441e0ab47834114754e7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33c027289ec1437c8e00c2282f682bea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d50ea40c19f44ba1a9d6678320cc023c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "47cf7475f9c94367b4c4839f9a0dccdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27520c8a56cf4199b4d8003d015e67f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7388277f52e74427ba614a8563436f0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1eaeeeee2455478d95b222c18ac8196f",
              "IPY_MODEL_4fafb13a492d457f8964fadc19131ca0",
              "IPY_MODEL_2975b3a13fcd4a2cb3bb0d5a9f4e8978"
            ],
            "layout": "IPY_MODEL_1b725c14c6f349a28b520757c631b3aa"
          }
        },
        "1eaeeeee2455478d95b222c18ac8196f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2c3df00d1fe44c1bb5e19684b2d55f4",
            "placeholder": "​",
            "style": "IPY_MODEL_033447a2eb1c4e41bcdec016543ea9bd",
            "value": "vocab.txt: 100%"
          }
        },
        "4fafb13a492d457f8964fadc19131ca0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f89046bde25b47768cfd1213906acd50",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6194a841279e40a6b7c73c3180c8390b",
            "value": 231508
          }
        },
        "2975b3a13fcd4a2cb3bb0d5a9f4e8978": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16aeeed6554b40f49108bc8d77d1a36a",
            "placeholder": "​",
            "style": "IPY_MODEL_ede286d49157435e833d32480d37a878",
            "value": " 232k/232k [00:00&lt;00:00, 4.72MB/s]"
          }
        },
        "1b725c14c6f349a28b520757c631b3aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2c3df00d1fe44c1bb5e19684b2d55f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "033447a2eb1c4e41bcdec016543ea9bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f89046bde25b47768cfd1213906acd50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6194a841279e40a6b7c73c3180c8390b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "16aeeed6554b40f49108bc8d77d1a36a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ede286d49157435e833d32480d37a878": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a741701c79964e8f81a8fdea41b07d8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e81f12f2e7fe423f85acdf5eff9e9a44",
              "IPY_MODEL_6a8f324c6f644e8d891985d67df63c91",
              "IPY_MODEL_b54469c3ff824b759bfa992cd3a2855c"
            ],
            "layout": "IPY_MODEL_c835aacb289f46f1bbbf35215f901e91"
          }
        },
        "e81f12f2e7fe423f85acdf5eff9e9a44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a80a06bd54124c2ab97eeef5b9db69fc",
            "placeholder": "​",
            "style": "IPY_MODEL_03039f1670eb49ef828cd4a0a8a762e5",
            "value": "tokenizer.json: 100%"
          }
        },
        "6a8f324c6f644e8d891985d67df63c91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59dd932ccf314429a7bb9bea583ae0ac",
            "max": 466247,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e68a087241e4467eb8c517036061c5aa",
            "value": 466247
          }
        },
        "b54469c3ff824b759bfa992cd3a2855c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2e3a4d27a1d4939aa3f2281efdecb7d",
            "placeholder": "​",
            "style": "IPY_MODEL_28cc6676acf04c088181b1697a5e3087",
            "value": " 466k/466k [00:00&lt;00:00, 7.53MB/s]"
          }
        },
        "c835aacb289f46f1bbbf35215f901e91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a80a06bd54124c2ab97eeef5b9db69fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03039f1670eb49ef828cd4a0a8a762e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59dd932ccf314429a7bb9bea583ae0ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e68a087241e4467eb8c517036061c5aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e2e3a4d27a1d4939aa3f2281efdecb7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28cc6676acf04c088181b1697a5e3087": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3458d93337574d0295661433752b9688": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff8df50e84d349d9bafc7a81dd28ab79",
              "IPY_MODEL_7136cd8e06aa498492cb53668e163f8d",
              "IPY_MODEL_aa373a29b1194b44842ce5985ebb1fe2"
            ],
            "layout": "IPY_MODEL_04ea2508f1774a04a8962f5ade60fd84"
          }
        },
        "ff8df50e84d349d9bafc7a81dd28ab79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1d4f2cd804c406fb52a34728c3d6724",
            "placeholder": "​",
            "style": "IPY_MODEL_9cf5e14d05404efd9ab69852fa30c149",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "7136cd8e06aa498492cb53668e163f8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8940221611d9412494987a64cc351fa5",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1ac943615e444bdeaab6eea5f65f1146",
            "value": 112
          }
        },
        "aa373a29b1194b44842ce5985ebb1fe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3210d19ca0d946299f6894739cc6f883",
            "placeholder": "​",
            "style": "IPY_MODEL_b66bd7f85c9942dcbbea281b9fe281ba",
            "value": " 112/112 [00:00&lt;00:00, 3.00kB/s]"
          }
        },
        "04ea2508f1774a04a8962f5ade60fd84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1d4f2cd804c406fb52a34728c3d6724": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cf5e14d05404efd9ab69852fa30c149": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8940221611d9412494987a64cc351fa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ac943615e444bdeaab6eea5f65f1146": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3210d19ca0d946299f6894739cc6f883": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b66bd7f85c9942dcbbea281b9fe281ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32ab2267fade4b84838bf06045254895": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b0c7049fb0054e43960f1fa7a36d14b4",
              "IPY_MODEL_809e3d796a1642ed9f205d1baaa2868f",
              "IPY_MODEL_d1d24dab07c74ffd82fd2d6346360232"
            ],
            "layout": "IPY_MODEL_c88e92a0b1ec4ad388b0671181013be5"
          }
        },
        "b0c7049fb0054e43960f1fa7a36d14b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f43fd066b0754136913cc75f91ad9af0",
            "placeholder": "​",
            "style": "IPY_MODEL_3d92ec2702ed48a0a5aeafb197b723db",
            "value": "1_Pooling/config.json: 100%"
          }
        },
        "809e3d796a1642ed9f205d1baaa2868f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afbe21d915e946768f95fb001171dc6f",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d8f075b0fc784355924fe2b68441610b",
            "value": 190
          }
        },
        "d1d24dab07c74ffd82fd2d6346360232": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41e402956d984167895d135372caece3",
            "placeholder": "​",
            "style": "IPY_MODEL_9ac6143a61c74b09b5713fac08edf9a1",
            "value": " 190/190 [00:00&lt;00:00, 2.25kB/s]"
          }
        },
        "c88e92a0b1ec4ad388b0671181013be5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f43fd066b0754136913cc75f91ad9af0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d92ec2702ed48a0a5aeafb197b723db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afbe21d915e946768f95fb001171dc6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8f075b0fc784355924fe2b68441610b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "41e402956d984167895d135372caece3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ac6143a61c74b09b5713fac08edf9a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shah-zeb-naveed/autogen-udemy-course/blob/main/Excercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyautogen -q"
      ],
      "metadata": {
        "id": "kplnofcC98VB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agents"
      ],
      "metadata": {
        "id": "T3tA5_d4iPsl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from autogen import ConversableAgent"
      ],
      "metadata": {
        "id": "dXWaQt-B5DGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_config = {\n",
        "    \"model\": \"gpt-3.5-turbo\",\n",
        "    \"api_key\": userdata.get(\"OPENAI_API_KEY\"),\n",
        "    \"temperature\" : 0.7\n",
        "}"
      ],
      "metadata": {
        "id": "fbZ3rQMZ609w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audience = ConversableAgent(\n",
        "    name = \"audience\",\n",
        "    llm_config = llm_config,\n",
        "    is_termination_msg = lambda msg: 'HAHA' in msg['content'].upper(),\n",
        "    system_message = 'You are a member of the audience of a comedy show that is hard to impress.'\n",
        ")"
      ],
      "metadata": {
        "id": "NKBY4kam1wit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comedian = ConversableAgent(\n",
        "    name = \"comedian\",\n",
        "    llm_config = llm_config,\n",
        "    max_consecutive_auto_reply=2,\n",
        "    system_message = 'You are a comedian that tells bad jokes.'\n",
        ")"
      ],
      "metadata": {
        "id": "3OCLkm341wPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comedian.initiate_chat(\n",
        "    audience,\n",
        "    message=\"Welcome to my standup comedy show! Are you ready for a night full of laughter?\",\n",
        "    max_turns = 2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNQ_-LOl1wNV",
        "outputId": "8b877d4e-d05c-4517-ceaa-7d71bc8c6335"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "comedian (to audience):\n",
            "\n",
            "Welcome to my standup comedy show! Are you ready for a night full of laughter?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "audience (to comedian):\n",
            "\n",
            "We'll see about that. Impress us with your jokes!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "comedian (to audience):\n",
            "\n",
            "Why did the tomato turn red? Because it saw the salad dressing!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "audience (to comedian):\n",
            "\n",
            "*polite chuckle* Not bad, not bad. Keep 'em coming.\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatResult(chat_id=None, chat_history=[{'content': 'Welcome to my standup comedy show! Are you ready for a night full of laughter?', 'role': 'assistant'}, {'content': \"We'll see about that. Impress us with your jokes!\", 'role': 'user'}, {'content': 'Why did the tomato turn red? Because it saw the salad dressing!', 'role': 'assistant'}, {'content': \"*polite chuckle* Not bad, not bad. Keep 'em coming.\", 'role': 'user'}], summary=\"*polite chuckle* Not bad, not bad. Keep 'em coming.\", cost={'usage_including_cached_inference': {'total_cost': 0.0006180000000000001, 'gpt-3.5-turbo-0125': {'cost': 0.0006180000000000001, 'prompt_tokens': 720, 'completion_tokens': 172, 'total_tokens': 892}}, 'usage_excluding_cached_inference': {'total_cost': 0.00015450000000000001, 'gpt-3.5-turbo-0125': {'cost': 0.00015450000000000001, 'prompt_tokens': 180, 'completion_tokens': 43, 'total_tokens': 223}}}, human_input=[])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Human-in-the-loop"
      ],
      "metadata": {
        "id": "rOWfMC48iWMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from autogen import ConversableAgent\n",
        "\n",
        "llm_config = {\n",
        "    \"model\": \"gpt-3.5-turbo\",\n",
        "    \"api_key\": userdata.get(\"OPENAI_API_KEY\"),\n",
        "    \"temperature\": 0.7\n",
        "}"
      ],
      "metadata": {
        "id": "Iauxc7OYJeiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_guesser = ConversableAgent(\n",
        "    name=\"agent_guesser\",\n",
        "    system_message=\"\"\"Let's play a game. I have a person in mind, and you have to guess it.\n",
        "    I'll respond with 'yes' or 'no' with a hint. Don't ask questions just make best\n",
        "    use of information you already have received and return person's name. Go ahead and start guessing!\"\"\",\n",
        "    max_consecutive_auto_reply=1,  # maximum number of consecutive auto-replies to a particular recipient\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode=\"TERMINATE\", # ask for human input at termination\n",
        ")\n",
        "\n",
        "agent_thinker = ConversableAgent(\n",
        "    \"agent_thinker\",\n",
        "    system_message=\"\"\"Let's play a game. Think of a famous personality, and I'll try to guess their name on every turn.\n",
        "    Respond with 'yes' or 'no'. If no, also provide a hint. Let's get started!\"\"\",\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode=\"NEVER\",  # default\n",
        ")\n"
      ],
      "metadata": {
        "id": "8LklKdV-P-0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = agent_thinker.initiate_chat(\n",
        "    agent_guesser,\n",
        "    message=\"Let's start. I have someone in mind.\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ol5wHFqTPeSb",
        "outputId": "be888573-1b84-49d9-cf6c-bbf10184887a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "agent_thinker (to agent_guesser):\n",
            "\n",
            "Let's start. I have someone in mind.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "agent_guesser (to agent_thinker):\n",
            "\n",
            "Is the person you're thinking of a fictional character?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "agent_thinker (to agent_guesser):\n",
            "\n",
            "No.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Please give feedback to agent_thinker. Press enter to skip and use auto-reply, or type 'exit' to stop the conversation: is this a politician?\n",
            "agent_guesser (to agent_thinker):\n",
            "\n",
            "is this a politician?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "agent_thinker (to agent_guesser):\n",
            "\n",
            "Yes.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "agent_guesser (to agent_thinker):\n",
            "\n",
            "Is the person you're thinking of a current world leader?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "agent_thinker (to agent_guesser):\n",
            "\n",
            "No.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Please give feedback to agent_thinker. Press enter to skip and use auto-reply, or type 'exit' to stop the conversation: exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code Executors"
      ],
      "metadata": {
        "id": "QXYTX5zClryt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "from autogen import ConversableAgent\n",
        "from autogen.coding import LocalCommandLineCodeExecutor\n",
        "\n",
        "\n",
        "executor = LocalCommandLineCodeExecutor(\n",
        "    timeout=10,\n",
        "    work_dir='code/'\n",
        ")\n",
        "\n",
        "code_executor_agent = ConversableAgent(\n",
        "    name=\"code_executor_agent\",\n",
        "    llm_config=False,\n",
        "    code_execution_config={\"executor\": executor},\n",
        "    human_input_mode=\"NEVER\",\n",
        ")\n",
        "\n",
        "message_with_code_block = \"\"\"\n",
        "Here's a code that solves your problem:\n",
        "```python\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a DataFrame with sample data\n",
        "data = pd.DataFrame({\n",
        "    'x': np.arange(10),\n",
        "    'y': np.random.randint(0, 10, 10)\n",
        "})\n",
        "\n",
        "# Plot the line plot\n",
        "plt.plot(data['x'], data['y'])\n",
        "plt.xlabel('X-axis')\n",
        "plt.ylabel('Y-axis')\n",
        "plt.title('Line Plot')\n",
        "plt.savefig('lineplot.png')\n",
        "plt.show()\n",
        "print('Line plot saved to lineplot.png')\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "reply = code_executor_agent.generate_reply(messages=[{\"role\": \"user\", \"content\": message_with_code_block}])\n",
        "print(reply)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwHPAVyjlrj3",
        "outputId": "cc992e03-bbfe-4186-8483-062af97b1686"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>>>>>>> EXECUTING CODE BLOCK (inferred language is python)...\n",
            "exitcode: 0 (execution succeeded)\n",
            "Code output: Figure(640x480)\n",
            "Line plot saved to lineplot.png\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "code_assistant_system_message = \"\"\"You are a helpful AI assistant.\n",
        "Solve tasks using your coding and language skills.\n",
        "In the following cases, suggest python code (in a python coding block) or shell script (in a sh coding block) for the user to execute.\n",
        "1. When you need to collect info, use the code to output the info you need, for example, browse or search the web, download/read a file, print the content of a webpage or a file, get the current date/time, check the operating system. After sufficient info is printed and the task is ready to be solved based on your language skill, you can solve the task by yourself.\n",
        "2. When you need to perform some task with code, use the code to perform the task and output the result. Finish the task smartly.\n",
        "Solve the task step by step if you need to. If a plan is not provided, explain your plan first. Be clear which step uses code, and which step uses your language skill.\n",
        "When using code, you must indicate the script type in the code block. The user cannot provide any other feedback or perform any other action beyond executing the code you suggest. The user can't modify your code. So do not suggest incomplete code which requires users to modify. Don't use a code block if it's not intended to be executed by the user.\n",
        "If you want the user to save the code in a file before executing it, put # filename: <filename> inside the code block as the first line. Don't include multiple code blocks in one response. Do not ask users to copy and paste the result. Instead, use 'print' function for the output when relevant. Check the execution result returned by the user.\n",
        "If the result indicates there is an error, fix the error and output the code again. Suggest the full code instead of partial code or code changes. If the error can't be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a different approach to try.\n",
        "When you find an answer, verify the answer carefully. Include verifiable evidence in your response if possible.\n",
        "Reply 'TERMINATE' in the end when everything is done.\n",
        "\"\"\"\n",
        "\n",
        "llm_config = {\n",
        "    \"model\": \"gpt-3.5-turbo\",\n",
        "    \"api_key\": userdata.get(\"OPENAI_API_KEY\"),\n",
        "    \"temperature\": 0.7\n",
        "}\n",
        "\n",
        "code_assistant = ConversableAgent(\n",
        "    \"code_assistant\",\n",
        "    llm_config=llm_config,\n",
        "    system_message=code_assistant_system_message,\n",
        "    code_execution_config=False,  # Turn off code execution for this agent.\n",
        ")"
      ],
      "metadata": {
        "id": "3xQyHoN_pVDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_result = code_executor_agent.initiate_chat(\n",
        "    code_assistant,\n",
        "    message=\"Write Python code to calculate the 23rd prime number\",\n",
        "    max_turns=2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyUDalSAqI0D",
        "outputId": "d3328f14-39ff-4c40-fcdc-8088f99fe57b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "code_executor_agent (to code_assistant):\n",
            "\n",
            "Write Python code to calculate the 23rd prime number\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "code_assistant (to code_executor_agent):\n",
            "\n",
            "```python\n",
            "# Calculate the 23rd prime number\n",
            "def is_prime(num):\n",
            "    if num < 2:\n",
            "        return False\n",
            "    for i in range(2, int(num**0.5) + 1):\n",
            "        if num % i == 0:\n",
            "            return False\n",
            "    return True\n",
            "\n",
            "count = 0\n",
            "num = 2\n",
            "\n",
            "while count < 23:\n",
            "    if is_prime(num):\n",
            "        count += 1\n",
            "    num += 1\n",
            "\n",
            "print(num - 1)\n",
            "```\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> EXECUTING CODE BLOCK (inferred language is python)...\n",
            "code_executor_agent (to code_assistant):\n",
            "\n",
            "exitcode: 0 (execution succeeded)\n",
            "Code output: 83\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "code_assistant (to code_executor_agent):\n",
            "\n",
            "The 23rd prime number is 83. The code has successfully calculated it. \n",
            "\n",
            "TERMINATE\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tools"
      ],
      "metadata": {
        "id": "MbhVVYEjaWwY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def scrape_wiki_main_page(url: str) -> str:\n",
        "    \"\"\"\n",
        "    Scrapes news content from wikipedia's main page.\n",
        "\n",
        "    Args:\n",
        "        url (str): The URL of the wikipedia page to scrape.\n",
        "\n",
        "    Returns:\n",
        "        str: The text content of the webpage.\n",
        "             Returns None if there is an error during the process.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        if response.status_code == 200:\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "            content = soup.get_text()\n",
        "            return content\n",
        "            content = content[content.find(\"In the news\"):content.find(\"Ongoing\")]\n",
        "            return content\n",
        "\n",
        "        else:\n",
        "            print(\"Failed to retrieve webpage. Status code:\", response.status_code)\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(\"An error occurred:\", e)\n",
        "        return None\n",
        "\n",
        "\n",
        "print(scrape_wiki_main_page('https://en.wikipedia.org/wiki/Main_Page'))"
      ],
      "metadata": {
        "id": "nWDySB3XaXrM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20f7519e-c7e9-4337-85dd-8cb48508f1cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "Wikipedia, the free encyclopedia\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Jump to content\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Main menu\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Main menu\n",
            "move to sidebar\n",
            "hide\n",
            "\n",
            "\n",
            "\n",
            "\t\tNavigation\n",
            "\t\n",
            "\n",
            "\n",
            "Main pageContentsCurrent eventsRandom articleAbout WikipediaContact usDonate\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\t\tContribute\n",
            "\t\n",
            "\n",
            "\n",
            "HelpLearn to editCommunity portalRecent changesUpload file\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Search\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Search\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Create account\n",
            "\n",
            "Log in\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Personal tools\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " Create account Log in\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\t\tPages for logged out editors learn more\n",
            "\n",
            "\n",
            "\n",
            "ContributionsTalk\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Main Page\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Main PageTalk\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "English\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ReadView sourceView history\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Tools\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Tools\n",
            "move to sidebar\n",
            "hide\n",
            "\n",
            "\n",
            "\n",
            "\t\tActions\n",
            "\t\n",
            "\n",
            "\n",
            "ReadView sourceView history\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\t\tGeneral\n",
            "\t\n",
            "\n",
            "\n",
            "What links hereRelated changesUpload fileSpecial pagesPermanent linkPage informationCite this pageGet shortened URLDownload QR codeWikidata item\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\t\tPrint/export\n",
            "\t\n",
            "\n",
            "\n",
            "Download as PDFPrintable version\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\t\tIn other projects\n",
            "\t\n",
            "\n",
            "\n",
            "Wikimedia CommonsWikimedia FoundationMediaWikiMeta-WikiWikimedia OutreachMultilingual WikisourceWikispeciesWikibooksWikidataWikifunctionsWikimaniaWikinewsWikiquoteWikisourceWikiversityWikivoyageWiktionary\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "From Wikipedia, the free encyclopedia\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Welcome to Wikipedia,\n",
            "the free encyclopedia that anyone can edit.\n",
            "6,817,162 articles in English\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "From today's featured article\n",
            "\n",
            "\n",
            "Kristin Chenoweth, who starred in the film\n",
            "\n",
            "Into Temptation is an independent drama film written and directed by Patrick Coyle. It tells the story of a prostitute—played by Kristin Chenoweth (pictured)—who confesses to a Catholic priest (Jeremy Sisto) that she plans to kill herself. The priest attempts to find her, and in doing so involves himself in the darker side of society. Partially inspired by Coyle's impressions of his father, the film's themes include temptation, sin, good and evil, redemption, celibacy, and the boundaries between providing counsel and getting personally involved in events. It was filmed and set in Coyle's hometown of Minneapolis. Into Temptation was optioned, but talks fell through due to complications from the 2008 global recession. It officially premiered on April 26, 2009, at the Newport Beach Film Festival, where Sisto won the \"Outstanding Achievement in Acting\" award. The film received generally positive reviews. (Full article...)\n",
            "\n",
            "\n",
            "Recently featured: \n",
            "Vance Drummond\n",
            "Death of Blair Peach\n",
            "Stanley Price Weir\n",
            "\n",
            "\n",
            "Archive\n",
            "By email\n",
            "More featured articles\n",
            "About\n",
            "\n",
            "Did you know ...\n",
            "\n",
            "\n",
            "\n",
            "Mirna El Helbawi\n",
            "\n",
            "... that Mirna El Helbawi (pictured) discovered a way to reconnect people in Gaza to the internet through donated eSIMs, and her organisation Connecting Humanity has connected more than 200,000 people so far?\n",
            "... that John Bennet Lawes started producing superphosphate, the first chemical manure produced in the world, from fossilised dinosaur dung on an industrial scale?\n",
            "... that World Pilots' Day is celebrated on 26 April to commemorate Fesa Evrensev's first flight, which took place 112 years ago today?\n",
            "... that the design of Genshin Impact's Furina has elements inspired by classical stories and musicals?\n",
            "... that Porter Robinson discovered that his song \"Ghost Voices\" had been nominated for a Grammy through Twitter?\n",
            "... that one of Ukraine's largest power plants was mostly destroyed by Russians in March 2024?\n",
            "... that Angela Doyinsola Aina helped to found the Black Mamas Matter Alliance to address the higher rate of maternal mortality faced by Black women in the United States?\n",
            "... that the live-action drama adaptation of Our Dining Table was filmed in the hometown of one of the lead actors?\n",
            "... that Fox bought a Philadelphia TV station started by a Fox?\n",
            "\n",
            "Archive\n",
            "Start a new article\n",
            "Nominate an article\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "In the news\n",
            "\n",
            "\n",
            "Manasseh Sogavare\n",
            "\n",
            "The Ownership, Unity and Responsibility Party, led by Prime Minister Manasseh Sogavare (pictured), wins the most seats in the Solomon Islands general election but falls short of a majority.\n",
            "NASA announces that the Voyager 1 space probe is sending readable data for the first time in five months.\n",
            "The HDZ-led coalition wins the most seats in the Croatian parliamentary election but falls short of a majority.\n",
            "Ich­thy­o­titan, the largest known marine reptile, is formally described.\n",
            "Flooding in the Persian Gulf and Arabian Peninsula leaves more than thirty people dead.\n",
            "\n",
            "Ongoing: \n",
            "Israel–Hamas war\n",
            "Myanmar civil war\n",
            "Russian invasion of Ukraine\n",
            "timeline\n",
            "War in Sudan\n",
            "timeline\n",
            "Recent deaths: \n",
            "Joel Breman\n",
            "Brian Tobin\n",
            "Dickey Betts\n",
            "Austin Murphy\n",
            "Terry Anderson\n",
            "Cecil Williams\n",
            "\n",
            "Nominate an article\n",
            "\n",
            "On this day\n",
            "\n",
            "April 26\n",
            "\n",
            "\n",
            "\n",
            "Lorenzo de' Medici\n",
            "\n",
            "1478 – In a conspiracy to replace the Medici family as rulers of the Republic of Florence, the Pazzi family attacked Lorenzo de' Medici (pictured) and killed his brother Giuliano at Florence Cathedral.\n",
            "1915 – First World War: Britain, France and Russia signed a secret treaty promising territory to Italy if it joined the war on their side.\n",
            "1933 – The Gestapo, the official secret police force of Nazi Germany, was established.\n",
            "1989 – A tornado struck the Manikganj District of Bangladesh and killed an estimated 1,300 people, making it the deadliest tornado in history.\n",
            "1994 – Just before landing at Nagoya Airport, Japan, the copilot of China Airlines Flight 140 inadvertently triggered the takeoff/go-around switch, causing the aircraft to crash and killing 264 of the 271 people on board.\n",
            "Marcus Aurelius   (b. 121)Alice Ayres  (d. 1885)S. J. V. Chelvanayakam  (d. 1977)\n",
            "\n",
            "More anniversaries: \n",
            "April 25\n",
            "April 26\n",
            "April 27\n",
            "\n",
            "\n",
            "Archive\n",
            "By email\n",
            "List of days of the year\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "From today's featured list\n",
            "\n",
            "Josh Brolin\n",
            "\n",
            "Avengers: Infinity War, a 2018 American superhero film based on the Marvel Comics superhero team the Avengers, won twenty-two awards from seventy-eight nominations, with particular recognition for its acting (mainly that of Josh Brolin – pictured) and visual effects. It received a nomination for Best Visual Effects at the 91st Academy Awards. The film received a nomination for Outstanding Achievement for Character Animation in a Live Action Production at the 46th Annie Awards. At the 72nd British Academy Film Awards, Avengers: Infinity War was nominated for Best Special Visual Effects. It received two nominations at the 24th Critics' Choice Awards. Composer Alan Silvestri received a nomination for Best Instrumental Composition at the Grammy Awards' 61st ceremony. The film won one of two nominations at the 45th Saturn Awards. (Full list...)\n",
            "\n",
            "\n",
            "Recently featured: \n",
            "Presidents of New York University\n",
            "World Heritage Sites in Laos\n",
            "Marvin Miller Man of the Year Award\n",
            "\n",
            "\n",
            "Archive\n",
            "More featured lists\n",
            "\n",
            "\n",
            "\n",
            "Today's featured picture\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Lichfield Cathedral is a Church of England cathedral in Lichfield, in the English county of Staffordshire. A cathedral was first built on the site in 700, by Bishop Headda, to house the bones of St Chad. The original wooden building was replaced by a Norman cathedral made from stone, which in turn was replaced by the present Gothic structure, begun in 1195. The fabric of the cathedral suffered in the English Civil War, when it was used as a defensive structure. In the 18th century the interior was extensively remodelled, with major structural work organised by James Wyatt; this involved removing the high altar to make a single worship area consisting of the choir and lady chapel, and adding a massive stone screen at the entrance to the choir. This photograph shows the choir of the cathedral, which was built around 1200.\n",
            "\n",
            "Photograph credit: David Iliff\n",
            "\n",
            "Recently featured: \n",
            "Madagascar stonechat\n",
            "Luis Walter Alvarez\n",
            "Bistorta officinalis\n",
            "\n",
            "\n",
            "Archive\n",
            "More featured pictures\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Other areas of Wikipedia\n",
            "\n",
            "Community portal – The central hub for editors, with resources, links, tasks, and announcements.\n",
            "Village pump – Forum for discussions about Wikipedia itself, including policies and technical issues.\n",
            "Site news – Sources of news about Wikipedia and the broader Wikimedia movement.\n",
            "Teahouse – Ask basic questions about using or editing Wikipedia.\n",
            "Help desk – Ask questions about using or editing Wikipedia.\n",
            "Reference desk – Ask research questions about encyclopedic topics.\n",
            "Content portals – A unique way to navigate the encyclopedia.\n",
            "\n",
            "Wikipedia's sister projects\n",
            "\n",
            "Wikipedia is written by volunteer editors and hosted by the Wikimedia Foundation, a non-profit organization that also hosts a range of other volunteer projects:\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "CommonsFree media repository\n",
            "\n",
            "\n",
            "\n",
            "MediaWikiWiki software development\n",
            "\n",
            "\n",
            "\n",
            "Meta-WikiWikimedia project coordination\n",
            "\n",
            "\n",
            "\n",
            "WikibooksFree textbooks and manuals\n",
            "\n",
            "\n",
            "\n",
            "WikidataFree knowledge base\n",
            "\n",
            "\n",
            "\n",
            "WikinewsFree-content news\n",
            "\n",
            "\n",
            "\n",
            "WikiquoteCollection of quotations\n",
            "\n",
            "\n",
            "\n",
            "WikisourceFree-content library\n",
            "\n",
            "\n",
            "\n",
            "WikispeciesDirectory of species\n",
            "\n",
            "\n",
            "\n",
            "WikiversityFree learning tools\n",
            "\n",
            "\n",
            "\n",
            "WikivoyageFree travel guide\n",
            "\n",
            "\n",
            "\n",
            "WiktionaryDictionary and thesaurus\n",
            "\n",
            "\n",
            "\n",
            "Wikipedia languages\n",
            "\n",
            "\n",
            "This Wikipedia is written in English. Many other Wikipedias are available; some of the largest are listed below.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1,000,000+ articles\n",
            "\n",
            "\n",
            "\n",
            "العربية\n",
            "مصرى\n",
            "Deutsch\n",
            "Español\n",
            "فارسی‎\n",
            "Français\n",
            "Italiano\n",
            "Nederlands\n",
            "日本語\n",
            "Polski\n",
            "Português\n",
            "Русский\n",
            "Svenska\n",
            "Українська\n",
            "Tiếng Việt\n",
            "中文\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "250,000+ articles\n",
            "\n",
            "\n",
            "\n",
            "Bahasa Indonesia\n",
            "Bahasa Melayu\n",
            "閩南語 / Bân-lâm-gú\n",
            "Български\n",
            "Català\n",
            "Čeština\n",
            "Dansk\n",
            "Esperanto\n",
            "Euskara\n",
            "עברית\n",
            "Հայերեն\n",
            "한국어\n",
            "Magyar\n",
            "Norsk bokmål\n",
            "Română\n",
            "Simple English\n",
            "Srpski\n",
            "Srpskohrvatski\n",
            "Suomi\n",
            "Türkçe\n",
            "Oʻzbekcha / ўзбекча\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "50,000+ articles\n",
            "\n",
            "\n",
            "\n",
            "Asturianu\n",
            "Azərbaycanca\n",
            "বাংলা\n",
            "Bosanski\n",
            "کوردی\n",
            "Eesti\n",
            "Ελληνικά\n",
            "Frysk\n",
            "Gaeilge\n",
            "Galego\n",
            "Hrvatski\n",
            "ქართული\n",
            "Kurdî\n",
            "Latviešu\n",
            "Lietuvių\n",
            "മലയാളം\n",
            "Македонски\n",
            "မြန်မာဘာသာ\n",
            "Norsk nynorsk\n",
            "ਪੰਜਾਬੀ\n",
            "Shqip\n",
            "Slovenčina\n",
            "Slovenščina\n",
            "ไทย\n",
            "తెలుగు\n",
            "اردو\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Retrieved from \"https://en.wikipedia.org/w/index.php?title=Main_Page&oldid=1212457119\"\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "49 languages\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "العربيةAzərbaycancaবাংলাБългарскиBosanskiCatalàČeštinaDanskDeutschEestiΕλληνικάEspañolEsperantoEuskaraفارسیFrançaisGalego한국어HrvatskiBahasa IndonesiaItalianoעבריתქართულიLatviešuLietuviųMagyarМакедонскиBahasa MelayuNederlands日本語Norsk bokmålNorsk nynorskPolskiPortuguêsRomânăРусскийSimple EnglishSlovenčinaSlovenščinaکوردیСрпски / srpskiSrpskohrvatski / српскохрватскиSuomiSvenskaไทยTürkçeУкраїнськаTiếng Việt中文\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " This page was last edited on 7 March 2024, at 23:59 (UTC).\n",
            "Text is available under the Creative Commons Attribution-ShareAlike License 4.0;\n",
            "additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.\n",
            "\n",
            "\n",
            "Privacy policy\n",
            "About Wikipedia\n",
            "Disclaimers\n",
            "Contact Wikipedia\n",
            "Code of Conduct\n",
            "Developers\n",
            "Statistics\n",
            "Cookie statement\n",
            "Mobile view\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Toggle limited content width\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from autogen import ConversableAgent\n",
        "\n",
        "llm_config = {\n",
        "    \"model\": \"gpt-3.5-turbo\",\n",
        "    \"api_key\": userdata.get(\"OPENAI_API_KEY\"),\n",
        "    \"temperature\": 0.7\n",
        "}\n",
        "\n",
        "# Let's first define the assistant agent that suggests tool calls.\n",
        "assistant = ConversableAgent(\n",
        "    name=\"assistant\",\n",
        "    llm_config=llm_config,\n",
        "    system_message=\"\"\"You are a helpful AI news bot.\n",
        "    You can pull content from wikipedia's main page.\n",
        "    URL: https://en.wikipedia.org/wiki/Main_Page. Once pulled, only share the top 3 stories.\n",
        "    Return 'TERMINATE' when the task is done.\"\"\",\n",
        ")\n",
        "\n",
        "# The user proxy agent is used for interacting with the assistant agent\n",
        "# and executes tool calls.\n",
        "user_proxy = ConversableAgent(\n",
        "    name=\"user_proxy\",\n",
        "    llm_config=False,\n",
        "    code_execution_config=False,\n",
        "    human_input_mode=\"NEVER\",\n",
        ")\n",
        "\n",
        "# Register the tool's information with the assistant agent.\n",
        "assistant.register_for_llm(\n",
        "    name=\"scrape_wiki_main_page\",\n",
        "    description=\"A tool for scraping today's news from wikipedia\"\n",
        ")(scrape_wiki_main_page)\n",
        "\n",
        "# Register the tool function with the user proxy agent.\n",
        "user_proxy.register_for_execution(\n",
        "    name=\"scrape_wiki_main_page\"\n",
        ")(scrape_wiki_main_page)"
      ],
      "metadata": {
        "id": "UX6ETsnI9JdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from autogen import Cache\n",
        "\n",
        "with Cache.disk() as cache:\n",
        "  chat_result = user_proxy.initiate_chat(\n",
        "      assistant,\n",
        "      message=\"What's hot in today's news?\",\n",
        "      max_turns=5\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ne63Xnr3abhD",
        "outputId": "5879119c-38a2-4d28-921d-854fde881909"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user_proxy (to assistant):\n",
            "\n",
            "What's hot in today's news?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "assistant (to user_proxy):\n",
            "\n",
            "***** Suggested tool call (call_QA4w3HFGiCTYHv6AJjTnNgkR): scrape_wiki_main_page *****\n",
            "Arguments: \n",
            "{\"url\":\"https://en.wikipedia.org/wiki/Main_Page\"}\n",
            "**************************************************************************************\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> EXECUTING FUNCTION scrape_wiki_main_page...\n",
            "user_proxy (to assistant):\n",
            "\n",
            "user_proxy (to assistant):\n",
            "\n",
            "***** Response from calling tool (call_QA4w3HFGiCTYHv6AJjTnNgkR) *****\n",
            "In the news\n",
            "\n",
            "\n",
            "Manasseh Sogavare\n",
            "\n",
            "The Ownership, Unity and Responsibility Party, led by Prime Minister Manasseh Sogavare (pictured), wins the most seats in the Solomon Islands general election but falls short of a majority.\n",
            "NASA announces that the Voyager 1 space probe is sending readable data for the first time in five months.\n",
            "The HDZ-led coalition wins the most seats in the Croatian parliamentary election but falls short of a majority.\n",
            "Ich­thy­o­titan, the largest known marine reptile, is formally described.\n",
            "Flooding in the Persian Gulf and Arabian Peninsula leaves more than thirty people dead.\n",
            "\n",
            "\n",
            "**********************************************************************\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "assistant (to user_proxy):\n",
            "\n",
            "Here are the top 3 news stories for today:\n",
            "1. The Ownership, Unity and Responsibility Party, led by Prime Minister Manasseh Sogavare, wins the most seats in the Solomon Islands general election but falls short of a majority.\n",
            "2. NASA announces that the Voyager 1 space probe is sending readable data for the first time in five months.\n",
            "3. The HDZ-led coalition wins the most seats in the Croatian parliamentary election but falls short of a majority.\n",
            "\n",
            "Would you like to know more about any of these stories?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "user_proxy (to assistant):\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "assistant (to user_proxy):\n",
            "\n",
            "TERMINATE\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from autogen import Cache\n",
        "\n",
        "with Cache.disk() as cache:\n",
        "  chat_result = user_proxy.initiate_chat(\n",
        "      assistant,\n",
        "      message=\"What's hot in today's news?\",\n",
        "      max_turns=2\n",
        "  )\n",
        "\n",
        "print(ConversableAgent.DEFAULT_SUMMARY_PROMPT)\n",
        "\n",
        "chat_result.summary"
      ],
      "metadata": {
        "id": "cI-sZ917PmEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sequential Chats"
      ],
      "metadata": {
        "id": "-xfWsZeDsx41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from autogen import ConversableAgent\n",
        "from google.colab import userdata\n",
        "\n",
        "llm_config = {\n",
        "    \"model\": \"gpt-3.5-turbo\",\n",
        "    \"api_key\": userdata.get(\"OPENAI_API_KEY\"),\n",
        "    \"temperature\": 0.7\n",
        "}"
      ],
      "metadata": {
        "id": "WKz7pHdsT7KA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A quest where an adventurer seeks help from wizard\n",
        "# to get past the guardian of the secret vault\n",
        "\n",
        "# Define the agents\n",
        "\n",
        "# The Adventurer Agent seeks advice from a Wizard on magical matters.\n",
        "adventurer_agent = ConversableAgent(\n",
        "    name=\"Adventurer_Agent\",\n",
        "    system_message=\"\"\"\n",
        "    You are a worthy adventurous hero seeking advice from a Wizard on magical matters.\n",
        "    Briefly communicate in less than 10 words.\"\"\",\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode=\"NEVER\",\n",
        ")\n",
        "\n",
        "# The Wizard Agent is an expert in magic and provides magical advice to the Adventurer.\n",
        "wizard_agent = ConversableAgent(\n",
        "    name=\"Wizard_Agent\",\n",
        "    system_message=\"\"\"\n",
        "    You are a wise and powerful Wizard. You provide magical advice to the\n",
        "    Adventurer. You know the passcode to the vault is Enigma.\n",
        "    Briefly communicate in less than 10 words.\"\"\",\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode=\"NEVER\",\n",
        ")\n",
        "\n",
        "# The guardian Agent guards the hidden gem and offers protection to the Adventurer.\n",
        "guardian_agent = ConversableAgent(\n",
        "    name=\"Guardian_Agent\",\n",
        "    system_message=\"\"\"You are the Guardian of the Hidden Gem, sworn to protect it from unworthy adventurers.\n",
        "    The passcode to the vault is Enigma. If adventurer mentions Enigma passcode, say 'Welcome!' otherwise say\n",
        "    'Incorrect Passcode'.  Briefly communicate in less than 10 words.\"\"\",\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode=\"NEVER\",\n",
        ")"
      ],
      "metadata": {
        "id": "OqptOmjtszJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start a sequence of two-agent chats.\n",
        "# Each element in the list is a dictionary that specifies the arguments\n",
        "# for the initiate_chat() method.\n",
        "\n",
        "sequence_of_chats = [\n",
        "    {\n",
        "      \"recipient\": wizard_agent,\n",
        "      \"message\": \"Help me get past the Guardian of the Hidden Gem in the secret vault.\",\n",
        "      \"max_turns\": 1,\n",
        "      \"summary_method\": \"reflection_with_llm\",\n",
        "    },\n",
        "    {\n",
        "      \"recipient\": guardian_agent,\n",
        "      \"message\": \"Allow me to enter the secret vault!\",\n",
        "      \"max_turns\": 1\n",
        "    }\n",
        "]\n",
        "\n",
        "chat_results = adventurer_agent.initiate_chats(sequence_of_chats)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtXvYPZruzHI",
        "outputId": "201108f5-1068-47ca-ef26-45d521f5f7f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "Adventurer_Agent (to Wizard_Agent):\n",
            "\n",
            "Help me get past the Guardian of the Hidden Gem in the secret vault.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Wizard_Agent (to Adventurer_Agent):\n",
            "\n",
            "Whisper \"Enigma\" to unlock the hidden gem's magic.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "Adventurer_Agent (to Guardian_Agent):\n",
            "\n",
            "Allow me to enter the secret vault!\n",
            "Context: \n",
            "Whisper \"Enigma\" to unlock the hidden gem's magic.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Guardian_Agent (to Adventurer_Agent):\n",
            "\n",
            "Welcome!\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nested Chat"
      ],
      "metadata": {
        "id": "fe7aWG3blXJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "poetry_agent = ConversableAgent(\n",
        "    name=\"Poet\",\n",
        "    system_message=\"You are an AI poet. Create only one stanza.\",\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode=\"NEVER\"\n",
        ")\n",
        "\n",
        "# parameters of initiate_chat() method\n",
        "sequence_of_chats = [\n",
        "    {\n",
        "        \"recipient\": wizard_agent,\n",
        "        \"max_turns\": 1,\n",
        "        \"message\": \"Help me get past the Guardian of the Hidden Gem in the secret vault.\",\n",
        "        \"summary_method\": \"reflection_with_llm\",\n",
        "        \"summary_prompt\": \"Concisely summarize the instructions given by wizard agent to communicate with guardian.\",\n",
        "    },\n",
        "    {\n",
        "        \"recipient\": guardian_agent,\n",
        "        \"max_turns\": 1,\n",
        "        \"message\": \"Allow me to enter the secret vault!\",\n",
        "        \"summary_method\": \"reflection_with_llm\",\n",
        "        \"summary_prompt\": \"Concisely summarize the quest.\",\n",
        "    },\n",
        "    {\n",
        "        \"recipient\": poetry_agent,\n",
        "        \"max_turns\": 1,\n",
        "        \"message\": \"Write a poem on my expedition.\",\n",
        "        \"summary_method\": \"last_msg\",\n",
        "    },\n",
        "]\n",
        "\n",
        "adventurer_agent.register_nested_chats(\n",
        "    sequence_of_chats,\n",
        "    # trigger determines if the agent should start nested chat given the sender agent.\n",
        "    # In this case, the adventurer agent will not start the nested chats if the sender is\n",
        "    # from the nested chats' recipient to avoid recursive calls.\n",
        "    trigger=lambda sender: sender not in [wizard_agent, guardian_agent, poetry_agent],\n",
        ")"
      ],
      "metadata": {
        "id": "g9DP00y8lbkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adventurer_agent.generate_reply(\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Hello!\"}]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 923
        },
        "id": "6_VR5Pkp0nL9",
        "outputId": "3bf05bd4-f32d-4cb8-a8ca-ff7e923d3f46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "Adventurer_Agent (to Wizard_Agent):\n",
            "\n",
            "Help me get past the Guardian of the Hidden Gem in the secret vault.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Wizard_Agent (to Adventurer_Agent):\n",
            "\n",
            "Whisper \"Enigma\" to unlock the hidden gem's magic.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "Adventurer_Agent (to Guardian_Agent):\n",
            "\n",
            "Allow me to enter the secret vault!\n",
            "Context: \n",
            "Whisper \"Enigma\" to unlock the hidden gem's magic.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Guardian_Agent (to Adventurer_Agent):\n",
            "\n",
            "Welcome!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "Adventurer_Agent (to Poet):\n",
            "\n",
            "Write a poem on my expedition.\n",
            "Context: \n",
            "Whisper \"Enigma\" to unlock the hidden gem's magic.\n",
            "Whisper \"Enigma\" to unlock the hidden gem's magic.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Poet (to Adventurer_Agent):\n",
            "\n",
            "In the heart of mystery's embrace, I tread\n",
            "Whispering \"Enigma\" to awaken the magic hidden ahead\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'In the heart of mystery\\'s embrace, I tread\\nWhispering \"Enigma\" to awaken the magic hidden ahead'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_results = user_proxy.initiate_chat(adventurer_agent, max_turns=1)\n",
        "chat_results\n",
        "\n",
        "\n",
        "# user_proxy ignores the message and relies on input\n",
        "# input routed as is to the first recipient"
      ],
      "metadata": {
        "id": "Zw55TcSWr5-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Impact of Role"
      ],
      "metadata": {
        "id": "9N76_15SzZpq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent = ConversableAgent(\n",
        "    \"chatbot\",\n",
        "    llm_config={\"config_list\": [llm_config]},\n",
        "    code_execution_config=False,  # Turn off code execution, by default it is off.\n",
        "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
        ")\n",
        "\n",
        "reply = agent.generate_reply(messages=[{\"content\": \"Tell me a joke.\", \"role\": \"user\"}])\n",
        "print(reply)\n",
        "\n",
        "reply = agent.generate_reply(messages=[{\"content\": \"Tell me a joke.\", \"role\": \"assistant\"}])\n",
        "print(reply)\n",
        "\n",
        "# role doesn't make a difference"
      ],
      "metadata": {
        "id": "KFEi6R9qzcHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Group Chat"
      ],
      "metadata": {
        "id": "H1R63d4f34dT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from autogen import ConversableAgent\n",
        "from google.colab import userdata\n",
        "\n",
        "llm_config = {\n",
        "    \"model\": \"gpt-3.5-turbo\",\n",
        "    \"api_key\": userdata.get(\"OPENAI_API_KEY\"),\n",
        "    \"temperature\": 0.7\n",
        "}"
      ],
      "metadata": {
        "id": "kOn-0qe92qnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the roles and their descriptions\n",
        "# a software engineering team:\n",
        "# scrum master\n",
        "# software engineer\n",
        "# product manager\n",
        "\n",
        "product_manager = ConversableAgent(\n",
        "    name=\"product_manager\",\n",
        "    system_message=\"You are an expert Product Manager working in a scrum team of an IT company. You like innovation and introducing new features as soon as possible.\",\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode=\"NEVER\",\n",
        "    description=\"Provides product requirements and priorities.\"\n",
        ")\n",
        "\n",
        "scrum_master = ConversableAgent(\n",
        "    name=\"scrum_master\",\n",
        "    system_message=\"You are a scrum master leading the 14-day sprints in an IT company. You provide technical leadership and make sure work is apporpirately planned.\",\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode=\"NEVER\",\n",
        "    description=\"Leads the sprint planning process.\"\n",
        ")\n",
        "\n",
        "software_engineer = ConversableAgent(\n",
        "    name=\"software_engineer\",\n",
        "    system_message=\"You are a senior software engineer in an IT company. You write software and technical documentation.\",\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode=\"NEVER\",\n",
        "    description=\"Provides insights on technical feasibility and effort estimation.\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "cDwnK3i9eub9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "allowed_transitions = {\n",
        "    product_manager: [scrum_master],\n",
        "    scrum_master: [software_engineer, product_manager],\n",
        "    software_engineer: [scrum_master],\n",
        "}"
      ],
      "metadata": {
        "id": "qkgWn8BNexEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from autogen import GroupChat, GroupChatManager\n",
        "\n",
        "# Create a GroupChat object and provide the list of agents\n",
        "sprint_planning_chat = GroupChat(\n",
        "    agents=[product_manager, scrum_master, software_engineer],\n",
        "    messages=[],\n",
        "    max_round=5,  # Setting a maximum round for the conversation,\n",
        "    send_introductions=True,\n",
        "    allowed_or_disallowed_speaker_transitions=allowed_transitions,\n",
        "    speaker_transitions_type=\"allowed\",\n",
        ")\n",
        "\n",
        "# Create a GroupChatManager object and provide the GroupChat object as input\n",
        "sprint_planning_chat_manager = GroupChatManager(\n",
        "    groupchat=sprint_planning_chat,\n",
        "    llm_config=llm_config  # Assuming the use of GPT-4 model\n",
        ")\n",
        "\n",
        "\n",
        "# Initiate the chat with the product_manager as the starting speaker\n",
        "chat_result = product_manager.initiate_chat(\n",
        "    sprint_planning_chat_manager,\n",
        "    message=\"We have a request to develop a website to track employee HR requests. How do we go about it?\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18IJA1Xy3Kzd",
        "outputId": "f237496b-c963-4794-f032-9e01313d014f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "product_manager (to chat_manager):\n",
            "\n",
            "We have a request to develop a website to track employee HR requests. How do we go about it?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "scrum_master (to chat_manager):\n",
            "\n",
            "Hello! To develop a website to track employee HR requests, we can start by breaking down the requirements into user stories or tasks. We will work closely with the product manager to understand the requirements and priorities. Next, the software engineers can provide insights on the technical feasibility and effort estimation for each task. Based on this information, we can plan out the tasks for the upcoming sprint and allocate resources accordingly. Does that sound good to everyone? Let's collaborate and get started on this project.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "software_engineer (to chat_manager):\n",
            "\n",
            "As a software engineer, I can offer my technical expertise to ensure that the website to track employee HR requests is developed efficiently and effectively. I will work closely with the team to analyze the requirements, provide insights on the technical feasibility of different features, and estimate the effort required for implementation. I will also contribute to the design and development of the system, ensuring that it meets the desired functionality and performance requirements. Let's collaborate and create a successful solution for this project.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "scrum_master (to chat_manager):\n",
            "\n",
            "That's great to hear! Your technical expertise will be invaluable in ensuring the successful development of the website to track employee HR requests. Your insights on technical feasibility, effort estimation, and system design will be crucial in shaping the project's direction. Let's work together closely to plan out the tasks for the upcoming sprint and create a solution that meets the product manager's requirements. Thank you for your dedication and collaboration!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "product_manager (to chat_manager):\n",
            "\n",
            "It's fantastic to see such collaboration and enthusiasm within the team! By working together closely and leveraging each team member's expertise, we can create a successful solution for tracking employee HR requests. Let's continue this momentum and strive to deliver innovative features as soon as possible. Keep up the great work, team!\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Speaker Selection"
      ],
      "metadata": {
        "id": "NcaK9jRUkB8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_speaker_selection(last_speaker, groupchat):\n",
        "    messages = groupchat.messages\n",
        "\n",
        "    # decide next turn\n",
        "    if last_speaker is scrum_master:\n",
        "        return product_manager\n",
        "    elif last_speaker is software_engineer:\n",
        "        return scrum_master\n",
        "    elif last_speaker is product_manager:\n",
        "        return software_engineer\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "sprint_planning_chat = GroupChat(\n",
        "    agents=[product_manager, scrum_master, software_engineer],\n",
        "    messages=[],\n",
        "    max_round=3,\n",
        "    send_introductions=True,\n",
        "    speaker_selection_method=custom_speaker_selection,\n",
        ")\n",
        "\n",
        "sprint_planning_chat_manager = GroupChatManager(\n",
        "    groupchat=sprint_planning_chat,\n",
        "    llm_config=llm_config\n",
        ")\n",
        "\n",
        "# Initiate the chat\n",
        "chat_result = product_manager.initiate_chat(\n",
        "    sprint_planning_chat_manager,\n",
        "    message=\"We have a request to develop a system to track employee HR requests. How do we go about it?\",\n",
        "    summary_method=\"reflection_with_llm\", # what's the point of this?\n",
        ")\n"
      ],
      "metadata": {
        "id": "UR6cpXy467EI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a230fe5-e92f-4975-afa9-fbc0f5750bec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "product_manager (to chat_manager):\n",
            "\n",
            "We have a request to develop a system to track employee HR requests. How do we go about it?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "software_engineer (to chat_manager):\n",
            "\n",
            "Hello, product_manager. To develop a system to track employee HR requests, we will need to gather detailed requirements from you. This will include understanding the types of HR requests to be tracked, the data to be captured for each request, user roles and permissions, workflow processes, reporting requirements, and any integrations with existing systems. Once we have a clear understanding of the requirements, we can work on designing the system architecture, identifying the technologies to be used, and estimating the development effort. It would be helpful if you could provide us with a detailed overview of the HR request tracking system you envision so that we can proceed with planning and implementation.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "scrum_master (to chat_manager):\n",
            "\n",
            "As the scrum master, I will facilitate the collaboration between the product manager and software engineer to ensure a clear understanding of the requirements for the HR request tracking system. We will work together to break down the project into manageable tasks and prioritize them based on business value and technical feasibility.\n",
            "\n",
            "I will also help the team create a sprint backlog with user stories, tasks, and acceptance criteria for each sprint. By organizing regular sprint planning meetings, daily stand-ups, and retrospectives, we will maintain a smooth development process and address any challenges that may arise during the sprint.\n",
            "\n",
            "Additionally, I will encourage continuous improvement by fostering a culture of learning and collaboration within the team. By providing technical leadership and guidance, I will ensure that the team stays on track to deliver high-quality solutions that meet the product manager's requirements.\n",
            "\n",
            "Let's kick off this sprint and work together to deliver a successful HR request tracking system!\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Transformation"
      ],
      "metadata": {
        "id": "GEkb3in5ZE_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import pprint\n",
        "\n",
        "from google.colab import userdata\n",
        "import autogen\n",
        "from autogen import ConversableAgent\n",
        "from autogen.agentchat.contrib.capabilities import transforms, transform_messages\n",
        "\n",
        "llm_config = {\n",
        "    \"model\": \"gpt-3.5-turbo\",\n",
        "    \"api_key\": userdata.get(\"OPENAI_API_KEY\"),\n",
        "    \"temperature\": 0.7\n",
        "}"
      ],
      "metadata": {
        "id": "vIrnE2WUZHh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_msg_transfrom = transforms.MessageHistoryLimiter(max_messages=3)\n",
        "\n",
        "# messages in OpenAI format\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Hello!\"},\n",
        "    {\"role\": \"assistant\", \"content\": [{\"type\": \"text\", \"text\": \"Hi! How can I help you?\"}]},\n",
        "    {\"role\": \"user\", \"content\": \"I just wanna talk...\"},\n",
        "    {\"role\": \"assistant\", \"content\": [{\"type\": \"text\", \"text\": \"Sure, I'm here for you. Sure, I'm here for you. Sure, I'm here for you. Sure, I'm here for you. \"}]},\n",
        "    {\"role\": \"user\", \"content\": \"Idk...\"},\n",
        "]\n",
        "\n",
        "processed_messages = max_msg_transfrom.apply_transform(copy.deepcopy(messages))\n",
        "pprint.pprint(processed_messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r90_huMDAfvP",
        "outputId": "68e54a6a-5831-46ed-d0ad-ea35bbe3457c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'content': 'I just wanna talk...', 'role': 'user'},\n",
            " {'content': [{'text': \"Sure, I'm here for you. Sure, I'm here for you. Sure, \"\n",
            "                       \"I'm here for you. Sure, I'm here for you. \",\n",
            "               'type': 'text'}],\n",
            "  'role': 'assistant'},\n",
            " {'content': 'Idk...', 'role': 'user'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_limit_transform = transforms.MessageTokenLimiter(max_tokens_per_message=3)\n",
        "processed_messages = token_limit_transform.apply_transform(copy.deepcopy(messages))\n",
        "pprint.pprint(processed_messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2s4Rb-CAemT",
        "outputId": "4a8d81cc-a02f-49d5-dac0-13665af7de5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'content': 'Hello!', 'role': 'user'},\n",
            " {'content': [{'text': 'Hi! How', 'type': 'text'}], 'role': 'assistant'},\n",
            " {'content': 'I just wanna', 'role': 'user'},\n",
            " {'content': [{'text': 'Sure, I', 'type': 'text'}], 'role': 'assistant'},\n",
            " {'content': 'Idk...', 'role': 'user'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assistant = autogen.AssistantAgent(\n",
        "    \"assistant\",\n",
        "    llm_config=llm_config,\n",
        ")\n",
        "\n",
        "transformer_handler = transform_messages.TransformMessages(\n",
        "    transforms=[\n",
        "        transforms.MessageHistoryLimiter(max_messages=5),\n",
        "        transforms.MessageTokenLimiter(max_tokens=100, max_tokens_per_message=5),\n",
        "    ]\n",
        ")\n",
        "\n",
        "transformer_handler.add_to_agent(assistant)\n",
        "\n",
        "# assistant will now received transformed messages!"
      ],
      "metadata": {
        "id": "WxrPAWQDAdR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import re\n",
        "from typing import Dict, List\n",
        "\n",
        "import autogen\n",
        "from autogen.agentchat.contrib.capabilities import transform_messages, transforms\n",
        "\n",
        "# apply_transform follows transform_messages.MessageTransform protocol\n",
        "class PIIRemover:\n",
        "    def __init__(self):\n",
        "        self._email_pattern = r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b\"\n",
        "        self._replacement_string = 'REDACTED'\n",
        "\n",
        "    def apply_transform(self, messages: List[Dict]) -> List[Dict]:\n",
        "        temp_messages = copy.deepcopy(messages)\n",
        "\n",
        "        for message in temp_messages:\n",
        "            if isinstance(message[\"content\"], str):\n",
        "                message[\"content\"] = re.sub(self._email_pattern, self._replacement_string, message[\"content\"])\n",
        "            elif isinstance(message[\"content\"], list):\n",
        "                for item in message[\"content\"]:\n",
        "                    if item[\"type\"] == \"text\":\n",
        "                        item[\"text\"] = re.sub(self._email_pattern, self._replacement_string, item[\"text\"])\n",
        "        return temp_messages\n",
        "\n",
        "    # borrowed from autogen MessageHistoryLimiter\n",
        "    def get_logs(self, pre_transform_messages, post_transform_messages):\n",
        "        pre_transform_messages_len = len(pre_transform_messages)\n",
        "        post_transform_messages_len = len(post_transform_messages)\n",
        "\n",
        "        if post_transform_messages_len < pre_transform_messages_len:\n",
        "            logs_str = (\n",
        "                f\"Removed {pre_transform_messages_len - post_transform_messages_len} messages. \"\n",
        "                f\"Number of messages reduced from {pre_transform_messages_len} to {post_transform_messages_len}.\"\n",
        "            )\n",
        "            return logs_str, True\n",
        "        return \"No messages were removed.\", False\n"
      ],
      "metadata": {
        "id": "YwhHEkHU75AB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assistant = autogen.AssistantAgent(\n",
        "    \"assistant\",\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode=\"NEVER\"\n",
        ")\n",
        "\n",
        "tranformer_handler = transform_messages.TransformMessages(transforms=[PIIRemover()])\n",
        "tranformer_handler.add_to_agent(assistant)"
      ],
      "metadata": {
        "id": "8lFyOIYEZG4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message = {\n",
        "    \"content\": \"contact support team at example_email@example.com for more queries.\",\n",
        "    \"role\" : 'user'\n",
        "}\n",
        "\n",
        "assistant.generate_reply(\n",
        "    messages=[message]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "_KVAiPURKkPz",
        "outputId": "23a11e68-8bd6-45f6-c1b9-9f62658ceef3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I cannot directly contact the support team for you. However, you can reach out to them yourself by sending an email to the provided email address \"REDACTED\" for any queries you may have. Is there anything else I can assist you with regarding this matter?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt Engineering: ReAct"
      ],
      "metadata": {
        "id": "rR8TG7c2lJmP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tavily-python chromadb langchain pyautogen -q"
      ],
      "metadata": {
        "id": "JE_I-Woyl2KL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adapted from Langchain's ReAct agent: https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/agents/react/agent.py#L79\n",
        "ReAct_prompt = \"\"\"\n",
        "Answer the following questions as best you can. You have access to tools provided.\n",
        "\n",
        "Use the following format:\n",
        "\n",
        "Question: the input question you must answer\n",
        "Thought: you should always think about what to do\n",
        "Action: the action to take\n",
        "Action Input: the input to the action\n",
        "Observation: the result of the action\n",
        "... (this process can repeat multiple times)\n",
        "Thought: I now know the final answer\n",
        "Final Answer: the final answer to the original input question\n",
        "\n",
        "Begin!\n",
        "Question: {input}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ErJbM9gQq8jP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import Annotated\n",
        "from google.colab import userdata\n",
        "\n",
        "import autogen\n",
        "from autogen import ConversableAgent, UserProxyAgent\n",
        "from autogen.cache import Cache\n",
        "from autogen.agentchat.contrib.capabilities import transforms, transform_messages\n",
        "from autogen.coding import LocalCommandLineCodeExecutor\n",
        "\n",
        "from tavily import TavilyClient\n",
        "\n",
        "llm_config = {\n",
        "    \"model\": \"gpt-4\",\n",
        "    \"api_key\": userdata.get(\"OPENAI_API_KEY\"),\n",
        "    \"temperature\": 0.7,\n",
        "    \"max_tokens\": 1000,\n",
        "}"
      ],
      "metadata": {
        "id": "FnHSaHWqlMWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['TAVILY_API_KEY'] = userdata.get('TAVILY_API_KEY')\n",
        "tavily = TavilyClient(api_key=os.environ[\"TAVILY_API_KEY\"])"
      ],
      "metadata": {
        "id": "OZk6hahBwpoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_tool(query: Annotated[str, \"The search query\"]) -> Annotated[str, \"The search results\"]:\n",
        "    return tavily.get_search_context(query=query, search_depth=\"advanced\")\n",
        "\n",
        "print(search_tool(query=\"Ronaldo's retirement date\"))"
      ],
      "metadata": {
        "id": "17Wt7rOCpE_w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad9e386e-02fe-4ff2-d6c7-4c4952dee3cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"[\\\"{\\\\\\\"url\\\\\\\": \\\\\\\"https://www.footballtransfers.com/en/transfer-news/uk-premier-league/2022/09/cristiano-ronaldo-retire-date-retirement\\\\\\\", \\\\\\\"content\\\\\\\": \\\\\\\"When will Cristiano Ronaldo retire? Cristiano Ronaldo will continue to play until at least 2024, the Manchester United star has confirmed. Ronaldo has revealed that he plans to play for Portugal at Euro 2024, at which point he will be 39 years old.\\\\\\\"}\\\", \\\"{\\\\\\\"url\\\\\\\": \\\\\\\"https://www.eurosport.com/football/world-cup/2022/has-cristiano-ronaldo-retired-was-qatar-2022-his-last-world-cup-which-club-does-portugal-superstar-n_sto9271431/story.shtml\\\\\\\", \\\\\\\"content\\\\\\\": \\\\\\\"There is just no keeping Cristiano Ronaldo out of the news, even now his Portugal team are no longer in the 2022 World Cup and he appears to be potentially on the brink of retirement from at least ...\\\\\\\"}\\\", \\\"{\\\\\\\"url\\\\\\\": \\\\\\\"https://www.mirror.co.uk/sport/football/news/cristiano-ronaldo-man-united-future-28045857\\\\\\\", \\\\\\\"content\\\\\\\": \\\\\\\"Ronaldo has scored 699 goals in club football and a total of 816 across his senior career and remains intent on adding to the 31 major honours he has won throughout his illustrious career. Most ...\\\\\\\"}\\\", \\\"{\\\\\\\"url\\\\\\\": \\\\\\\"https://talksport.com/football/1249125/cristiano-ronaldo-retirement-plans-man-utd-portugal-last-world-cup/\\\\\\\", \\\\\\\"content\\\\\\\": \\\\\\\"Cristiano Ronaldo says he plans to retire from football at the age of 40, and also admitted this World Cup will probably be his last. The Portuguese, who turns 38 in February, has enjoyed a spectac\\\\\\\\u2026\\\\\\\"}\\\", \\\"{\\\\\\\"url\\\\\\\": \\\\\\\"https://www.sportingnews.com/us/soccer/news/cristiano-ronaldo-retirement-date-age-last-world-cup/uaaltzqpdymzz09ccd2z10fh\\\\\\\", \\\\\\\"content\\\\\\\": \\\\\\\"What CR7 has said about retirement date Despite speculation earlier this year that Ronaldo might be close to retiring from football, the former Manchester United player has regularly dismissed ...\\\\\\\"}\\\"]\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create agents\n",
        "user_proxy = UserProxyAgent(\n",
        "    name=\"user_proxy\",\n",
        "    is_termination_msg=lambda x: x.get(\"content\", \"\") and x.get(\"content\", \"\").rstrip().upper().endswith(\"TERMINATE\"),\n",
        "    human_input_mode=\"NEVER\",\n",
        "    code_execution_config=False#{\"executor\": LocalCommandLineCodeExecutor(work_dir=\"coding\")},\n",
        ")"
      ],
      "metadata": {
        "id": "AuqjzrpuvGYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assistant = autogen.AssistantAgent(\n",
        "    name=\"Assistant\",\n",
        "    system_message=\"You are an AI Assistant. Only use tools you have been provided with. Reply TERMINATE when the task is done.\",\n",
        "    llm_config=llm_config,\n",
        ")"
      ],
      "metadata": {
        "id": "jPWh0YAlvWC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# register tool\n",
        "autogen.register_function(\n",
        "    search_tool,\n",
        "    caller=assistant,\n",
        "    executor=user_proxy,\n",
        "    name=\"search_tool\",\n",
        "    description=\"Search the web for the given query\",\n",
        ")"
      ],
      "metadata": {
        "id": "yo3GOdbFvXFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def react_prompt_message(sender, recipient, context):\n",
        "    return ReAct_prompt.format(input=context[\"question\"])"
      ],
      "metadata": {
        "id": "LtSAMX-1wO3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with Cache.disk(cache_seed=5) as cache:\n",
        "  user_proxy.initiate_chat(\n",
        "    assistant,\n",
        "    question=\"Why is NVIDIA's stock down today\",\n",
        "    max_turns=4,\n",
        "    message=react_prompt_message\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4NjoMUJlLzb",
        "outputId": "1a8be950-d611-409c-d1fe-875dd5cda7f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user_proxy (to Assistant):\n",
            "\n",
            "\n",
            "Answer the following questions as best you can. You have access to tools provided.\n",
            "\n",
            "Use the following format:\n",
            "\n",
            "Question: the input question you must answer\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take\n",
            "Action Input: the input to the action\n",
            "Observation: the result of the action\n",
            "... (this process can repeat multiple times)\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "\n",
            "Begin!\n",
            "Question: Why is NVIDIA's stock down today\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Assistant (to user_proxy):\n",
            "\n",
            "Thought: I need to look up the latest news or reports for NVIDIA to understand why their stock is down today.\n",
            "Action: Use the search_tool function to find information about NVIDIA's stock performance.\n",
            "Action Input: { \"query\": \"Why is NVIDIA's stock down today\" }\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "user_proxy (to Assistant):\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Assistant (to user_proxy):\n",
            "\n",
            "***** Suggested tool call (call_zRMPoxnDSIIVWoW8WdnnDRvb): search_tool *****\n",
            "Arguments: \n",
            "\n",
            "{\n",
            "\"query\": \"Why is NVIDIA's stock down today\"\n",
            "}\n",
            "****************************************************************************\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> EXECUTING FUNCTION search_tool...\n",
            "user_proxy (to Assistant):\n",
            "\n",
            "user_proxy (to Assistant):\n",
            "\n",
            "***** Response from calling tool (call_zRMPoxnDSIIVWoW8WdnnDRvb) *****\n",
            "\"[\\\"{\\\\\\\"url\\\\\\\": \\\\\\\"https://www.marketwatch.com/story/nvidias-stock-heads-for-dramatic-reverse-lower-not-seen-in-over-two-years-8654b5c7\\\\\\\", \\\\\\\"content\\\\\\\": \\\\\\\"The last time Nvidia's stock NVDA, +3.10% was up at least 5% intraday but ended the session more than 5% lower was June 9, 2017, when it rose as much as 5.4% but finished off 6.5%, according to ...\\\\\\\"}\\\", \\\"{\\\\\\\"url\\\\\\\": \\\\\\\"https://www.fool.com/investing/2024/04/19/why-nvidia-stock-plunged-10-today/\\\\\\\", \\\\\\\"content\\\\\\\": \\\\\\\"Shares of the AI chip leader got swept up in a broader AI sell-off after one analyst noted that Super Micro Computer ( SMCI 5.21%), another AI stock leader, failed to report preliminary revenue ...\\\\\\\"}\\\", \\\"{\\\\\\\"url\\\\\\\": \\\\\\\"https://finance.yahoo.com/news/why-nvidias-stock-sell-off-matters-and-what-people-are-saying-about-it-123044984.html\\\\\\\", \\\\\\\"content\\\\\\\": \\\\\\\"Market darling Nvidia's ( NVDA) stock fell into correction territory, defined as a 10% decline from a recent high. At its low of around $830 midway through Tuesday's session, the stock was down 12 ...\\\\\\\"}\\\", \\\"{\\\\\\\"url\\\\\\\": \\\\\\\"https://finance.yahoo.com/quote/NVDA/news/\\\\\\\", \\\\\\\"content\\\\\\\": \\\\\\\"The world's second-biggest memory chipmaker and Nvidia supplier reported a 2.89 trillion won ($2.1 billion) operating profit for the January-March quarter versus a loss of 3.4 trillion won a year ...\\\\\\\"}\\\", \\\"{\\\\\\\"url\\\\\\\": \\\\\\\"https://finance.yahoo.com/news/why-nvidia-nvda-stock-trading-193751029.html\\\\\\\", \\\\\\\"content\\\\\\\": \\\\\\\"Nvidia is up 58.8% since the beginning of the year, but at $764.31 per share it is still trading 19.5% below its 52-week high of $950.02 from March 2024. Investors who bought $1,000 worth of ...\\\\\\\"}\\\"]\"\n",
            "**********************************************************************\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Assistant (to user_proxy):\n",
            "\n",
            "Observation: The search results suggest various reasons for NVIDIA's stock being down. These include a broader AI sell-off triggered by another AI stock leader, Super Micro Computer, failing to report preliminary revenue. The stock also fell into correction territory, defined as a 10% decline from a recent high. \n",
            "\n",
            "Thought: Based on the search results, it seems that the stock's decline may be due to a combination of factors, including a broader market trend and specific company performance.\n",
            "Final Answer: NVIDIA's stock decline is likely due to a combination of a broader AI market sell-off and the stock entering correction territory, which means it has fallen at least 10% from a recent high.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "user_proxy (to Assistant):\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Assistant (to user_proxy):\n",
            "\n",
            "TERMINATE\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def generate_tool_schema(tool):\n",
        "#     \"\"\"\n",
        "#     Define the tool's schema based on tool.args_schema for LLM config\n",
        "#     \"\"\"\n",
        "#     tool_schema = {\n",
        "#         \"name\": tool.name.lower().replace(\" \", \"_\"),\n",
        "#         \"description\": tool.description,\n",
        "#         \"parameters\": {\n",
        "#             \"type\": \"object\",\n",
        "#             \"properties\": {},\n",
        "#             \"required\": [],\n",
        "#         },\n",
        "#     }\n",
        "\n",
        "#     if tool.args is not None:\n",
        "#         tool_schema[\"parameters\"][\"properties\"] = tool.args\n",
        "\n",
        "#     return tool_schema\n",
        "\n",
        "# generate_tool_schema(search_tool)\n",
        "\n",
        "# llm_config = {\n",
        "#     \"functions\": [generate_tool_schema(search_tool)],\n",
        "#     \"config_list\": [llm_config],\n",
        "#     \"timeout\" : 120\n",
        "# }"
      ],
      "metadata": {
        "id": "fUhwFicbsVD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ReAct with Teachability"
      ],
      "metadata": {
        "id": "QeBxRYKwybTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from autogen.agentchat.contrib.capabilities import teachability\n",
        "\n",
        "# Instantiate Teachability capability\n",
        "teachability = teachability.Teachability(\n",
        "    verbosity=3,  # 0 for basic info, 1 to add memory operations, 2 for analyzer messages, 3 for memo lists.\n",
        "    reset_db=True,\n",
        "    path_to_db_dir=\"./teachability_db\",\n",
        "    recall_threshold=1.5,  # Squared L2, Higher numbers allow more (but less relevant) memos to be recalled.\n",
        ")\n",
        "\n",
        "# add Teachability capability\n",
        "teachability.add_to_agent(assistant)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whLQGBmCyZ9c",
        "outputId": "0c79e350-4443-4d1b-8dbf-7c7b156d1461"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CLEARING MEMORY\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# starts with empty vector store\n",
        "\n",
        "with Cache.disk() as cache:\n",
        "  user_proxy.initiate_chat(\n",
        "      assistant,\n",
        "      question=\"What is LLAMA 3's release date?\",\n",
        "      max_turns=4,\n",
        "      message=react_prompt_message\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vMsJC5qn0wPW",
        "outputId": "b223a53f-f471-4de7-cee5-64df43174791"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user_proxy (to Assistant):\n",
            "\n",
            "\n",
            "Answer the following questions as best you can. You have access to tools provided.\n",
            "\n",
            "Use the following format:\n",
            "\n",
            "Question: the input question you must answer\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take\n",
            "Action Input: the input to the action\n",
            "Observation: the result of the action\n",
            "... (this process can repeat multiple times)\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "\n",
            "Begin!\n",
            "Question: Who is the current prime minister of germany?\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Assistant (to analyzer):\n",
            "\n",
            "\n",
            "Answer the following questions as best you can. You have access to tools provided.\n",
            "\n",
            "Use the following format:\n",
            "\n",
            "Question: the input question you must answer\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take\n",
            "Action Input: the input to the action\n",
            "Observation: the result of the action\n",
            "... (this process can repeat multiple times)\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "\n",
            "Begin!\n",
            "Question: Who is the current prime minister of germany?\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Assistant (to analyzer):\n",
            "\n",
            "Does any part of the TEXT ask the agent to perform a task or solve a problem? Answer with just one word, yes or no.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "analyzer (to Assistant):\n",
            "\n",
            "# INSTRUCTIONS\n",
            "Does any part of the TEXT ask the agent to perform a task or solve a problem? Answer with just one word, yes or no.\n",
            "\n",
            "# TEXT\n",
            "\n",
            "Answer the following questions as best you can. You have access to tools provided.\n",
            "\n",
            "Use the following format:\n",
            "\n",
            "Question: the input question you must answer\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take\n",
            "Action Input: the input to the action\n",
            "Observation: the result of the action\n",
            "... (this process can repeat multiple times)\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "\n",
            "Begin!\n",
            "Question: Who is the current prime minister of germany?\n",
            "\n",
            "\n",
            "# INSTRUCTIONS\n",
            "Does any part of the TEXT ask the agent to perform a task or solve a problem? Answer with just one word, yes or no.\n",
            "***** Suggested tool call (call_fbrGOE8fEdYHoHwdShoKiK95): search_tool *****\n",
            "Arguments: \n",
            "{\"query\":\"Does any part of the TEXT ask the agent to perform a task or solve a problem?\"}\n",
            "****************************************************************************\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Assistant (to analyzer):\n",
            "\n",
            "\n",
            "Answer the following questions as best you can. You have access to tools provided.\n",
            "\n",
            "Use the following format:\n",
            "\n",
            "Question: the input question you must answer\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take\n",
            "Action Input: the input to the action\n",
            "Observation: the result of the action\n",
            "... (this process can repeat multiple times)\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "\n",
            "Begin!\n",
            "Question: Who is the current prime minister of germany?\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Assistant (to analyzer):\n",
            "\n",
            "Briefly copy any advice from the TEXT that may be useful for a similar but different task in the future. But if no advice is present, just respond with 'none'.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "analyzer (to Assistant):\n",
            "\n",
            "none\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Assistant (to analyzer):\n",
            "\n",
            "\n",
            "Answer the following questions as best you can. You have access to tools provided.\n",
            "\n",
            "Use the following format:\n",
            "\n",
            "Question: the input question you must answer\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take\n",
            "Action Input: the input to the action\n",
            "Observation: the result of the action\n",
            "... (this process can repeat multiple times)\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "\n",
            "Begin!\n",
            "Question: Who is the current prime minister of germany?\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Assistant (to analyzer):\n",
            "\n",
            "Does the TEXT contain information that could be committed to memory? Answer with just one word, yes or no.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "analyzer (to Assistant):\n",
            "\n",
            "# INSTRUCTIONS\n",
            "Does the TEXT contain information that could be committed to memory? Answer with just one word, yes or no.\n",
            "\n",
            "# TEXT\n",
            "\n",
            "Answer the following questions as best you can. You have access to tools provided.\n",
            "\n",
            "Use the following format:\n",
            "\n",
            "Question: the input question you must answer\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take\n",
            "Action Input: the input to the action\n",
            "Observation: the result of the action\n",
            "... (this process can repeat multiple times)\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "\n",
            "Begin!\n",
            "Question: Who is the current prime minister of germany?\n",
            "\n",
            "\n",
            "# INSTRUCTIONS\n",
            "Does the TEXT contain information that could be committed to memory? Answer with just one word, yes or no.\n",
            "***** Suggested tool call (call_bHcVJ4sTBZ9HS0o5W44EUlkl): search_tool *****\n",
            "Arguments: \n",
            "{\"query\":\"Who is the current prime minister of Germany?\"}\n",
            "****************************************************************************\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Assistant (to analyzer):\n",
            "\n",
            "\n",
            "Answer the following questions as best you can. You have access to tools provided.\n",
            "\n",
            "Use the following format:\n",
            "\n",
            "Question: the input question you must answer\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take\n",
            "Action Input: the input to the action\n",
            "Observation: the result of the action\n",
            "... (this process can repeat multiple times)\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "\n",
            "Begin!\n",
            "Question: Who is the current prime minister of germany?\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Assistant (to analyzer):\n",
            "\n",
            "Imagine that the user forgot this information in the TEXT. How would they ask you for this information? Include no other text in your response.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "analyzer (to Assistant):\n",
            "\n",
            "Question: Who is the current prime minister of Germany?\n",
            "Thought: Think about how the user would ask for this information.\n",
            "Action: Search for the current prime minister of Germany.\n",
            "Action Input: \"current prime minister of Germany\"\n",
            "Observation: The search results display the name of the current chancellor of Germany.\n",
            "Thought: I now know the final answer\n",
            "Final Answer: The current chancellor of Germany is Angela Merkel.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Assistant (to analyzer):\n",
            "\n",
            "\n",
            "Answer the following questions as best you can. You have access to tools provided.\n",
            "\n",
            "Use the following format:\n",
            "\n",
            "Question: the input question you must answer\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take\n",
            "Action Input: the input to the action\n",
            "Observation: the result of the action\n",
            "... (this process can repeat multiple times)\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "\n",
            "Begin!\n",
            "Question: Who is the current prime minister of germany?\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Assistant (to analyzer):\n",
            "\n",
            "Copy the information from the TEXT that should be committed to memory. Add no explanation.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "analyzer (to Assistant):\n",
            "\n",
            "Answer the following questions as best you can. You have access to tools provided.\n",
            "\n",
            "Use the following format:\n",
            "\n",
            "Question: the input question you must answer\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take\n",
            "Action Input: the input to the action\n",
            "Observation: the result of the action\n",
            "... (this process can repeat multiple times)\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "\n",
            "Begin!\n",
            "Question: Who is the current prime minister of germany?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "REMEMBER THIS QUESTION-ANSWER PAIR\n",
            "\n",
            "INPUT-OUTPUT PAIR ADDED TO VECTOR DATABASE:\n",
            "  ID\n",
            "    1\n",
            "  INPUT\n",
            "    Question: Who is the current prime minister of Germany?\n",
            "Thought: Think about how the user would ask for this information.\n",
            "Action: Search for the current prime minister of Germany.\n",
            "Action Input: \"current prime minister of Germany\"\n",
            "Observation: The search results display the name of the current chancellor of Germany.\n",
            "Thought: I now know the final answer\n",
            "Final Answer: The current chancellor of Germany is Angela Merkel.\n",
            "  OUTPUT\n",
            "    Answer the following questions as best you can. You have access to tools provided.\n",
            "\n",
            "Use the following format:\n",
            "\n",
            "Question: the input question you must answer\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take\n",
            "Action Input: the input to the action\n",
            "Observation: the result of the action\n",
            "... (this process can repeat multiple times)\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "\n",
            "Begin!\n",
            "Question: Who is the current prime minister of germany?\n",
            "\n",
            "LIST OF MEMOS\n",
            "  ID: 1\n",
            "    INPUT TEXT: Question: Who is the current prime minister of Germany?\n",
            "Thought: Think about how the user would ask for this information.\n",
            "Action: Search for the current prime minister of Germany.\n",
            "Action Input: \"current prime minister of Germany\"\n",
            "Observation: The search results display the name of the current chancellor of Germany.\n",
            "Thought: I now know the final answer\n",
            "Final Answer: The current chancellor of Germany is Angela Merkel.\n",
            "    OUTPUT TEXT: Answer the following questions as best you can. You have access to tools provided.\n",
            "\n",
            "Use the following format:\n",
            "\n",
            "Question: the input question you must answer\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take\n",
            "Action Input: the input to the action\n",
            "Observation: the result of the action\n",
            "... (this process can repeat multiple times)\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "\n",
            "Begin!\n",
            "Question: Who is the current prime minister of germany?\n",
            "Assistant (to user_proxy):\n",
            "\n",
            "***** Suggested tool call (call_wBlU6N3hfx6sCqMocXKM6NGg): search_tool *****\n",
            "Arguments: \n",
            "{\"query\":\"current prime minister of Germany\"}\n",
            "****************************************************************************\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> EXECUTING FUNCTION search_tool...\n",
            "user_proxy (to Assistant):\n",
            "\n",
            "user_proxy (to Assistant):\n",
            "\n",
            "***** Response from calling tool (call_wBlU6N3hfx6sCqMocXKM6NGg) *****\n",
            "\"[\\\"{\\\\\\\"url\\\\\\\": \\\\\\\"https://www.nytimes.com/live/2021/12/08/world/germany-scholz-merkel\\\\\\\", \\\\\\\"content\\\\\\\": \\\\\\\"The oath for an incoming chancellor, as laid out in article 56 of Germany\\\\\\\\u2019s Constitution, reads as follows: \\\\\\\\u201cI swear that I will dedicate my strength to the good of the German people, that I will enhance their prosperity, avert harm from them, respect and defend the Constitution and the laws of the federal state, fulfill my duty conscientiously and exercise justice toward everyone. But one of Ms. Merkel\\\\\\\\u2019s choices intrigued many and set the German Twittersphere alight: \\\\\\\\u201cDu hast den Farbfilm vergessen,\\\\\\\\u201d or \\\\\\\\u201cYou Forgot the Color Film,\\\\\\\\u201d a 1970s hit from the Communist East by Nina Hagen, who later emigrated to the West and went on to become West Germany\\\\\\\\u2019s punk rock idol of the 1980s.\\\\\\\\n After announcing tough restrictions for unvaccinated people and an intention to make vaccinations mandatory, the incoming chancellor, Olaf Scholz, took the popular step this week of tapping Karl Lauterbach, a Harvard-trained public health expert and medical doctor, to run the health ministry.\\\\\\\\nMr. Lauterbach, often in a bow tie, has been a fixture on television debate shows and in newspaper interviews since the pandemic began. For the photographer Herlinde Koelbl, the end of Angela Merkel\\\\\\\\u2019s tenure as Germany\\\\\\\\u2019s chancellor isn\\\\\\\\u2019t just the end of a political era \\\\\\\\u2014 it\\\\\\\\u2019s also the end of one of the longest-running art projects in world politics.\\\\\\\\n In addition, a proposed law would require the installation of solar panels on the roofs of all new commercial buildings, with the amount of solar-powered energy in the country to be tripled by the end of this decade.\\\\\\\\n\\\\\\\"}\\\", \\\"{\\\\\\\"url\\\\\\\": \\\\\\\"https://www.npr.org/2021/12/08/1062130622/germany-new-chancellor-olaf-scholz-coalition-government\\\\\\\", \\\\\\\"content\\\\\\\": \\\\\\\"This Is The Candidate To Beat In The Race To Become Germany's Next Leader\\\\\\\\nOne of the reasons he and his party prevailed in the federal election is that in Scholz, Germans see a continuation of Merkel's governing style: Scholz is a calm, steady hand in a crisis and a pragmatic leader who strives for compromise.\\\\\\\\n World\\\\\\\\nWhat you need to know about Germany's new chancellor and coalition government\\\\\\\\nRob Schmitz\\\\\\\\nMembers of three German parties at the signing of a coalition agreement are (from left) Social Democrats Norbert Walter-Borjan, Saskia Esken and new Chancellor Olaf Scholz, Free Democrat Christian Lindner, and the Green party's Robert Habeck and Annalena Baerbock on Tuesday in Berlin.\\\\\\\\n \\\\\\\\\\\\\\\"We commit to a community of democracies across the globe and I am very grateful to President Biden for emphasizing the importance of multilateralism and at the same time, we are committed to what unites particular nations: the idea of freedom, the rule of law, democracy and respect for human rights. Andreas Gora/Pool/Getty Images\\\\\\\\nhide caption\\\\\\\\nClaudia Roth, designated minister of state for culture, Anne Spiegel, designated family affairs minister, Robert Habeck, designated minister of economy, energy and climate protection, Annalena Baerbock, designated foreign minister, Cem Ozdemir, designated agriculture minister, and Steffi Lemke, designated environment minister, present themselves to the media on Monday in Berlin.\\\\\\\\n Carsten Koall/Getty Images\\\\\\\\nhide caption\\\\\\\\nMembers of three German parties at the signing of a coalition agreement are (from left) Social Democrats Norbert Walter-Borjan, Saskia Esken and new Chancellor Olaf Scholz, Free Democrat Christian Lindner, and the Green party's Robert Habeck and Annalena Baerbock on Tuesday in Berlin.\\\\\\\\n\\\\\\\"}\\\", \\\"{\\\\\\\"url\\\\\\\": \\\\\\\"https://www.bbc.com/news/world-europe-59575773\\\\\\\", \\\\\\\"content\\\\\\\": \\\\\\\"Ready for power: Team Scholz promises a new Germany\\\\\\\\nAfrican diaspora with 'a voice' in Germany\\\\\\\\nDefeated Merkel heir prepared to resign as leader\\\\\\\\nGermany lose in Austria as Nagelsmann woe continues\\\\\\\\nAustria hand Germany a second straight defeat as Julian Nagelsmann's reign continues to get off to a difficult start.\\\\\\\\n Nagelsmann loses on home debut as Germany boss\\\\\\\\nJulian Nagelsmann's home debut as Germany coach ends in defeat as the Euro 2024 hosts are beaten by Turkey in a friendly.\\\\\\\\nBerlin on edge for Erdogan after fierce Israel criticism\\\\\\\\nIsrael's war with Hamas takes centre stage as Turkey's leader meets Chancellor Olaf Scholz in Berlin.\\\\\\\\n Beta Terms By using the Beta Site, you agree that such use is at your own risk and you know that the Beta Site may include known or unknown bugs or errors, that we have no obligation to make this Beta Site available with or without charge for any period of time, nor to make it available at all, and that nothing in these Beta Terms or your use of the Beta Site creates any employment relationship between you and us. Although Russia has denied plans to invade its neighbour, Angela Merkel agreed with US President Joe Biden and the leaders of the UK, France and Italy late on Tuesday that they would adopt a joint strategy to respond by imposing \\\\\\\\\\\\\\\"significant and severe harm on the Russian economy\\\\\\\\\\\\\\\".\\\\\\\\n Mr Scholz, a soft-spoken 63-year-old, steered the Social Democrats to election victory in late September, positioning himself as the continuity candidate because he played a key role in the Merkel government as vice-chancellor.\\\\\\\\n\\\\\\\"}\\\", \\\"{\\\\\\\"url\\\\\\\": \\\\\\\"https://en.wikipedia.org/wiki/Olaf_Scholz\\\\\\\", \\\\\\\"content\\\\\\\": \\\\\\\"On 10 August 2020, SPD party leadership agreed that it would nominate Scholz to be the party's candidate for Chancellor of Germany at the 2021 federal election.[105] Scholz is usually grouped with the moderate wing of the SPD,[106] and his nomination was seen by Die Tageszeitung as marking a decline of the party's left.[107]\\\\\\\\nScholz led the SPD to a narrow victory in the election, with the party receiving 25.8% of the second votes and 206 seats in the Bundestag.[108] Following this victory, Scholz was widely considered to be the most likely next Chancellor of Germany in a traffic light coalition with The Greens and the Free Democratic Party.[109]\\\\\\\\nOn 24 November, the SPD, Green and FDP reached a coalition agreement, naming Scholz as the new German chancellor.[110]\\\\\\\\nChancellor of Germany, 2021\\\\\\\\u2013present[edit]\\\\\\\\nScholz was elected Chancellor by the Bundestag on 8 December 2021, with 395 votes in favour and 303 against.[111] Also in June 2021, Scholz oversaw the Federal Central Tax Office's purchase of information regarding German citizens using Dubai for tax avoidance and evasion.[58]\\\\\\\\nScholz was criticized in the context of the Wirecard scandal; serious misconduct by the Federal Financial Supervisory Authority (BaFin), which is under the responsibility of the Federal Ministry of Finance, is alleged to have contributed to the longevity of the fraudulent business.[59][60] During Scholz's time in office, the Ministry of Finance was one of the subjects of parliamentary inquiry into the scandal, but Scholz has denied any personal responsibility.[61][62] Journalist Hermann-Josef Tenhagen criticized this version of the transaction tax on the basis that it would disproportionately affect lower-income individuals.[77] A report by the Kiel Institute for the World Economy commissioned by the Federal Government in 2020 certified the same deficiencies in the tax concept that Tenhagen had already pointed out.[78]\\\\\\\\nDuring his tenure as minister of finance, Scholz prioritized not taking on new government debt and limiting public spending.[50] In 2018, he suggested the creation of an EU-wide unemployment insurance system to make the Eurozone more resilient to future economic shocks.[79]\\\\\\\\nIn September 2019, Scholz negotiated the climate package in a key role for the SPD. Alongside fellow Social Democrats J\\\\\\\\u00f6rg Asmussen and Thomas Oppermann, Scholz was reported in the media to be a possible successor to Sch\\\\\\\\u00e4uble in the post of Finance Minister at the time; whilst Sch\\\\\\\\u00e4uble remained in post, the talks to form a coalition were ultimately successful.[39]\\\\\\\\nIn a paper compiled in late 2014, Scholz and Sch\\\\\\\\u00e4uble proposed redirecting revenue from the solidarity surcharge on income and corporate tax (Solidarit\\\\\\\\u00e4tszuschlag) to subsidize the federal states' interest payments.[40]\\\\\\\\nUnder Scholz's leadership, the Social Democrats won the 2015 state election in Hamburg, receiving around 47% of the vote.[41] In January 2022, The New York Times reported intensifying concerns from the US and other NATO allies about the Scholz government's \\\\\\\\\\\\\\\"evident hesitation to take forceful measures\\\\\\\\\\\\\\\" against Russia in the 2021\\\\\\\\u20132022 Russo-Ukrainian crisis.[149]\\\\\\\\nThe Scholz government initially refused to send weapons to Ukraine, citing existing German policy and financial support for the Eastern European country.[150] As late as 15 February, Scholz was quoted by TASS as saying \\\\\\\\\\\\\\\"the way out of the crisis in Ukraine is to implement the Steinmeier formula\\\\\\\\\\\\\\\", a mechanism of granting a special status to Donbass.[151]\\\\\\\"}\\\", \\\"{\\\\\\\"url\\\\\\\": \\\\\\\"https://www.cnn.com/2021/12/08/europe/germany-olaf-scholz-chancellor-inauguration-intl/index.html\\\\\\\", \\\\\\\"content\\\\\\\": \\\\\\\"CNN values your feedback\\\\\\\\nOlaf Scholz appointed as Germany\\\\\\\\u2019s new chancellor, replacing Angela Merkel after 16 years\\\\\\\\nOlaf Scholz has been sworn in as Germany\\\\\\\\u2019s new Chancellor on Wednesday, bringing to an end Angela Merkel\\\\\\\\u2019s four terms at the helm of Europe\\\\\\\\u2019s largest economy.\\\\\\\\nScholz, the leader of the Social Democratic Party (SPD), won the secret vote in the Parliament as expected, a culmination of months of negotiations following the SPD\\\\\\\\u2019s narrow victory in September\\\\\\\\u2019s federal elections.\\\\\\\\n The Greens will be taking over the foreign ministry, the environment ministry and the newly created ministry of the economy and climate, while the FDP will be in charge of the finance ministry, the justice department and the education ministry.\\\\\\\\n \\\\\\\\u201cScholz seems to partly owe his success [in the election] to posing as [Merkel\\\\\\\\u2019s] worthy heir during the campaign, calm and unassuming \\\\\\\\u2013 and with his hands folded into a Merkel-style rhombus in a picture that went viral,\\\\\\\\u201d Holger Schmieding, the chief economist at Berenberg Bank, wrote in an analyst note on Wednesday. Merkel, who watched the parliamentary proceedings from the visitors\\\\\\\\u2019 gallery alongside former chancellor Gerhard Schroeder, received applause from lawmakers when name-checked by the parliamentary president Baerbel Bas.\\\\\\\\nHaving led Germany for 16 years and 16 days, Merkel has narrowly missed on becoming the longest serving post-war Chancellor, trailing Helmut Kohl by mere 10 days.\\\\\\\\n The 63-year-old life-long member of the SPD served as the Labor and Social Affairs minister in Merkel\\\\\\\\u2019s first coalition government in the late 2000s.\\\\\\\"}\\\"]\"\n",
            "**********************************************************************\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "LOOK FOR RELEVANT MEMOS, AS QUESTION-ANSWER PAIRS\n",
            "\n",
            "INPUT-OUTPUT PAIR RETRIEVED FROM VECTOR DATABASE:\n",
            "  INPUT1\n",
            "    Question: Who is the current prime minister of Germany?\n",
            "Thought: Think about how the user would ask for this information.\n",
            "Action: Search for the current prime minister of Germany.\n",
            "Action Input: \"current prime minister of Germany\"\n",
            "Observation: The search results display the name of the current chancellor of Germany.\n",
            "Thought: I now know the final answer\n",
            "Final Answer: The current chancellor of Germany is Angela Merkel.\n",
            "  OUTPUT\n",
            "    Answer the following questions as best you can. You have access to tools provided.\n",
            "\n",
            "Use the following format:\n",
            "\n",
            "Question: the input question you must answer\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take\n",
            "Action Input: the input to the action\n",
            "Observation: the result of the action\n",
            "... (this process can repeat multiple times)\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "\n",
            "Begin!\n",
            "Question: Who is the current prime minister of germany?\n",
            "  DISTANCE\n",
            "    1.256562948506396\n",
            "Assistant (to analyzer):\n",
            "\n",
            "\"[\\\"{\\\\\\\"url\\\\\\\": \\\\\\\"https://www.nytimes.com/live/2021/12/08/world/germany-scholz-merkel\\\\\\\", \\\\\\\"content\\\\\\\": \\\\\\\"The oath for an incoming chancellor, as laid out in article 56 of Germany\\\\\\\\u2019s Constitution, reads as follows: \\\\\\\\u201cI swear that I will dedicate my strength to the good of the German people, that I will enhance their prosperity, avert harm from them, respect and defend the Constitution and the laws of the federal state, fulfill my duty conscientiously and exercise justice toward everyone. But one of Ms. Merkel\\\\\\\\u2019s choices intrigued many and set the German Twittersphere alight: \\\\\\\\u201cDu hast den Farbfilm vergessen,\\\\\\\\u201d or \\\\\\\\u201cYou Forgot the Color Film,\\\\\\\\u201d a 1970s hit from the Communist East by Nina Hagen, who later emigrated to the West and went on to become West Germany\\\\\\\\u2019s punk rock idol of the 1980s.\\\\\\\\n After announcing tough restrictions for unvaccinated people and an intention to make vaccinations mandatory, the incoming chancellor, Olaf Scholz, took the popular step this week of tapping Karl Lauterbach, a Harvard-trained public health expert and medical doctor, to run the health ministry.\\\\\\\\nMr. Lauterbach, often in a bow tie, has been a fixture on television debate shows and in newspaper interviews since the pandemic began. For the photographer Herlinde Koelbl, the end of Angela Merkel\\\\\\\\u2019s tenure as Germany\\\\\\\\u2019s chancellor isn\\\\\\\\u2019t just the end of a political era \\\\\\\\u2014 it\\\\\\\\u2019s also the end of one of the longest-running art projects in world politics.\\\\\\\\n In addition, a proposed law would require the installation of solar panels on the roofs of all new commercial buildings, with the amount of solar-powered energy in the country to be tripled by the end of this decade.\\\\\\\\n\\\\\\\"}\\\", \\\"{\\\\\\\"url\\\\\\\": \\\\\\\"https://www.npr.org/2021/12/08/1062130622/germany-new-chancellor-olaf-scholz-coalition-government\\\\\\\", \\\\\\\"content\\\\\\\": \\\\\\\"This Is The Candidate To Beat In The Race To Become Germany's Next Leader\\\\\\\\nOne of the reasons he and his party prevailed in the federal election is that in Scholz, Germans see a continuation of Merkel's governing style: Scholz is a calm, steady hand in a crisis and a pragmatic leader who strives for compromise.\\\\\\\\n World\\\\\\\\nWhat you need to know about Germany's new chancellor and coalition government\\\\\\\\nRob Schmitz\\\\\\\\nMembers of three German parties at the signing of a coalition agreement are (from left) Social Democrats Norbert Walter-Borjan, Saskia Esken and new Chancellor Olaf Scholz, Free Democrat Christian Lindner, and the Green party's Robert Habeck and Annalena Baerbock on Tuesday in Berlin.\\\\\\\\n \\\\\\\\\\\\\\\"We commit to a community of democracies across the globe and I am very grateful to President Biden for emphasizing the importance of multilateralism and at the same time, we are committed to what unites particular nations: the idea of freedom, the rule of law, democracy and respect for human rights. Andreas Gora/Pool/Getty Images\\\\\\\\nhide caption\\\\\\\\nClaudia Roth, designated minister of state for culture, Anne Spiegel, designated family affairs minister, Robert Habeck, designated minister of economy, energy and climate protection, Annalena Baerbock, designated foreign minister, Cem Ozdemir, designated agriculture minister, and Steffi Lemke, designated environment minister, present themselves to the media on Monday in Berlin.\\\\\\\\n Carsten Koall/Getty Images\\\\\\\\nhide caption\\\\\\\\nMembers of three German parties at the signing of a coalition agreement are (from left) Social Democrats Norbert Walter-Borjan, Saskia Esken and new Chancellor Olaf Scholz, Free Democrat Christian Lindner, and the Green party's Robert Habeck and Annalena Baerbock on Tuesday in Berlin.\\\\\\\\n\\\\\\\"}\\\", \\\"{\\\\\\\"url\\\\\\\": \\\\\\\"https://www.bbc.com/news/world-europe-59575773\\\\\\\", \\\\\\\"content\\\\\\\": \\\\\\\"Ready for power: Team Scholz promises a new Germany\\\\\\\\nAfrican diaspora with 'a voice' in Germany\\\\\\\\nDefeated Merkel heir prepared to resign as leader\\\\\\\\nGermany lose in Austria as Nagelsmann woe continues\\\\\\\\nAustria hand Germany a second straight defeat as Julian Nagelsmann's reign continues to get off to a difficult start.\\\\\\\\n Nagelsmann loses on home debut as Germany boss\\\\\\\\nJulian Nagelsmann's home debut as Germany coach ends in defeat as the Euro 2024 hosts are beaten by Turkey in a friendly.\\\\\\\\nBerlin on edge for Erdogan after fierce Israel criticism\\\\\\\\nIsrael's war with Hamas takes centre stage as Turkey's leader meets Chancellor Olaf Scholz in Berlin.\\\\\\\\n Beta Terms By using the Beta Site, you agree that such use is at your own risk and you know that the Beta Site may include known or unknown bugs or errors, that we have no obligation to make this Beta Site available with or without charge for any period of time, nor to make it available at all, and that nothing in these Beta Terms or your use of the Beta Site creates any employment relationship between you and us. Although Russia has denied plans to invade its neighbour, Angela Merkel agreed with US President Joe Biden and the leaders of the UK, France and Italy late on Tuesday that they would adopt a joint strategy to respond by imposing \\\\\\\\\\\\\\\"significant and severe harm on the Russian economy\\\\\\\\\\\\\\\".\\\\\\\\n Mr Scholz, a soft-spoken 63-year-old, steered the Social Democrats to election victory in late September, positioning himself as the continuity candidate because he played a key role in the Merkel government as vice-chancellor.\\\\\\\\n\\\\\\\"}\\\", \\\"{\\\\\\\"url\\\\\\\": \\\\\\\"https://en.wikipedia.org/wiki/Olaf_Scholz\\\\\\\", \\\\\\\"content\\\\\\\": \\\\\\\"On 10 August 2020, SPD party leadership agreed that it would nominate Scholz to be the party's candidate for Chancellor of Germany at the 2021 federal election.[105] Scholz is usually grouped with the moderate wing of the SPD,[106] and his nomination was seen by Die Tageszeitung as marking a decline of the party's left.[107]\\\\\\\\nScholz led the SPD to a narrow victory in the election, with the party receiving 25.8% of the second votes and 206 seats in the Bundestag.[108] Following this victory, Scholz was widely considered to be the most likely next Chancellor of Germany in a traffic light coalition with The Greens and the Free Democratic Party.[109]\\\\\\\\nOn 24 November, the SPD, Green and FDP reached a coalition agreement, naming Scholz as the new German chancellor.[110]\\\\\\\\nChancellor of Germany, 2021\\\\\\\\u2013present[edit]\\\\\\\\nScholz was elected Chancellor by the Bundestag on 8 December 2021, with 395 votes in favour and 303 against.[111] Also in June 2021, Scholz oversaw the Federal Central Tax Office's purchase of information regarding German citizens using Dubai for tax avoidance and evasion.[58]\\\\\\\\nScholz was criticized in the context of the Wirecard scandal; serious misconduct by the Federal Financial Supervisory Authority (BaFin), which is under the responsibility of the Federal Ministry of Finance, is alleged to have contributed to the longevity of the fraudulent business.[59][60] During Scholz's time in office, the Ministry of Finance was one of the subjects of parliamentary inquiry into the scandal, but Scholz has denied any personal responsibility.[61][62] Journalist Hermann-Josef Tenhagen criticized this version of the transaction tax on the basis that it would disproportionately affect lower-income individuals.[77] A report by the Kiel Institute for the World Economy commissioned by the Federal Government in 2020 certified the same deficiencies in the tax concept that Tenhagen had already pointed out.[78]\\\\\\\\nDuring his tenure as minister of finance, Scholz prioritized not taking on new government debt and limiting public spending.[50] In 2018, he suggested the creation of an EU-wide unemployment insurance system to make the Eurozone more resilient to future economic shocks.[79]\\\\\\\\nIn September 2019, Scholz negotiated the climate package in a key role for the SPD. Alongside fellow Social Democrats J\\\\\\\\u00f6rg Asmussen and Thomas Oppermann, Scholz was reported in the media to be a possible successor to Sch\\\\\\\\u00e4uble in the post of Finance Minister at the time; whilst Sch\\\\\\\\u00e4uble remained in post, the talks to form a coalition were ultimately successful.[39]\\\\\\\\nIn a paper compiled in late 2014, Scholz and Sch\\\\\\\\u00e4uble proposed redirecting revenue from the solidarity surcharge on income and corporate tax (Solidarit\\\\\\\\u00e4tszuschlag) to subsidize the federal states' interest payments.[40]\\\\\\\\nUnder Scholz's leadership, the Social Democrats won the 2015 state election in Hamburg, receiving around 47% of the vote.[41] In January 2022, The New York Times reported intensifying concerns from the US and other NATO allies about the Scholz government's \\\\\\\\\\\\\\\"evident hesitation to take forceful measures\\\\\\\\\\\\\\\" against Russia in the 2021\\\\\\\\u20132022 Russo-Ukrainian crisis.[149]\\\\\\\\nThe Scholz government initially refused to send weapons to Ukraine, citing existing German policy and financial support for the Eastern European country.[150] As late as 15 February, Scholz was quoted by TASS as saying \\\\\\\\\\\\\\\"the way out of the crisis in Ukraine is to implement the Steinmeier formula\\\\\\\\\\\\\\\", a mechanism of granting a special status to Donbass.[151]\\\\\\\"}\\\", \\\"{\\\\\\\"url\\\\\\\": \\\\\\\"https://www.cnn.com/2021/12/08/europe/germany-olaf-scholz-chancellor-inauguration-intl/index.html\\\\\\\", \\\\\\\"content\\\\\\\": \\\\\\\"CNN values your feedback\\\\\\\\nOlaf Scholz appointed as Germany\\\\\\\\u2019s new chancellor, replacing Angela Merkel after 16 years\\\\\\\\nOlaf Scholz has been sworn in as Germany\\\\\\\\u2019s new Chancellor on Wednesday, bringing to an end Angela Merkel\\\\\\\\u2019s four terms at the helm of Europe\\\\\\\\u2019s largest economy.\\\\\\\\nScholz, the leader of the Social Democratic Party (SPD), won the secret vote in the Parliament as expected, a culmination of months of negotiations following the SPD\\\\\\\\u2019s narrow victory in September\\\\\\\\u2019s federal elections.\\\\\\\\n The Greens will be taking over the foreign ministry, the environment ministry and the newly created ministry of the economy and climate, while the FDP will be in charge of the finance ministry, the justice department and the education ministry.\\\\\\\\n \\\\\\\\u201cScholz seems to partly owe his success [in the election] to posing as [Merkel\\\\\\\\u2019s] worthy heir during the campaign, calm and unassuming \\\\\\\\u2013 and with his hands folded into a Merkel-style rhombus in a picture that went viral,\\\\\\\\u201d Holger Schmieding, the chief economist at Berenberg Bank, wrote in an analyst note on Wednesday. Merkel, who watched the parliamentary proceedings from the visitors\\\\\\\\u2019 gallery alongside former chancellor Gerhard Schroeder, received applause from lawmakers when name-checked by the parliamentary president Baerbel Bas.\\\\\\\\nHaving led Germany for 16 years and 16 days, Merkel has narrowly missed on becoming the longest serving post-war Chancellor, trailing Helmut Kohl by mere 10 days.\\\\\\\\n The 63-year-old life-long member of the SPD served as the Labor and Social Affairs minister in Merkel\\\\\\\\u2019s first coalition government in the late 2000s.\\\\\\\"}\\\"]\"\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Assistant (to analyzer):\n",
            "\n",
            "Does any part of the TEXT ask the agent to perform a task or solve a problem? Answer with just one word, yes or no.\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-d1fc12781125>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mCache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   user_proxy.initiate_chat(\n\u001b[0m\u001b[1;32m      5\u001b[0m       \u001b[0massistant\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0mquestion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Who is the current prime minister of germany?\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogen/agentchat/conversable_agent.py\u001b[0m in \u001b[0;36minitiate_chat\u001b[0;34m(self, recipient, clear_history, silent, cache, max_turns, summary_method, summary_args, message, **kwargs)\u001b[0m\n\u001b[1;32m    982\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmsg2send\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 984\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg2send\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecipient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    985\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_chat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecipient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogen/agentchat/conversable_agent.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_append_oai_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"assistant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecipient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m             \u001b[0mrecipient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreceive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_reply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogen/agentchat/conversable_agent.py\u001b[0m in \u001b[0;36mreceive\u001b[0;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrequest_reply\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mrequest_reply\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreply_at_receive\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msender\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m         \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_reply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_messages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msender\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msender\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msender\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msender\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogen/agentchat/conversable_agent.py\u001b[0m in \u001b[0;36mgenerate_reply\u001b[0;34m(self, messages, sender, **kwargs)\u001b[0m\n\u001b[1;32m   1906\u001b[0m         \u001b[0;31m# Call the hookable method that gives registered hooks a chance to process the last message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1907\u001b[0m         \u001b[0;31m# Message modifications do not affect the incoming messages or self._oai_messages.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1908\u001b[0;31m         \u001b[0mmessages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_last_received_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m         \u001b[0;31m# Call the hookable method that gives registered hooks a chance to process all messages.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogen/agentchat/conversable_agent.py\u001b[0m in \u001b[0;36mprocess_last_received_message\u001b[0;34m(self, messages)\u001b[0m\n\u001b[1;32m   2689\u001b[0m         \u001b[0mprocessed_user_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_content\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2690\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhook_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2691\u001b[0;31m             \u001b[0mprocessed_user_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_user_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2692\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprocessed_user_content\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0muser_content\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2693\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmessages\u001b[0m  \u001b[0;31m# No hooks actually modified the user's message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogen/agentchat/contrib/capabilities/teachability.py\u001b[0m in \u001b[0;36mprocess_last_received_message\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mexpanded_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemo_store\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_memo_id\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0mexpanded_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consider_memo_retrieval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;31m# Try to store any user teachings in new memos to be used in the future.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogen/agentchat/contrib/capabilities/teachability.py\u001b[0m in \u001b[0;36m_consider_memo_retrieval\u001b[0;34m(self, comment)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;31m# Next, if the comment involves a task, then extract and generalize the task before using it as the lookup key.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         response = self._analyze(\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0mcomment\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;34m\"Does any part of the TEXT ask the agent to perform a task or solve a problem? Answer with just one word, yes or no.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogen/agentchat/contrib/capabilities/teachability.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(self, text_to_analyze, analysis_instructions)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0mrecipient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyzer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_to_analyze\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbosity\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         )  # Put the message in the analyzer's list.\n\u001b[0;32m--> 234\u001b[0;31m         self.teachable_agent.send(\n\u001b[0m\u001b[1;32m    235\u001b[0m             \u001b[0mrecipient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyzer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0manalysis_instructions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbosity\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         )  # Request the reply.\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogen/agentchat/conversable_agent.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_append_oai_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"assistant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecipient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m             \u001b[0mrecipient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreceive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_reply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogen/agentchat/conversable_agent.py\u001b[0m in \u001b[0;36mreceive\u001b[0;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrequest_reply\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mrequest_reply\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreply_at_receive\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msender\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m         \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_reply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_messages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msender\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msender\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msender\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msender\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogen/agentchat/conversable_agent.py\u001b[0m in \u001b[0;36mgenerate_reply\u001b[0;34m(self, messages, sender, **kwargs)\u001b[0m\n\u001b[1;32m   1919\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_match_trigger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply_func_tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"trigger\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msender\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1921\u001b[0;31m                 \u001b[0mfinal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreply_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msender\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msender\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreply_func_tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"config\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1922\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogen/agentchat/contrib/text_analyzer_agent.py\u001b[0m in \u001b[0;36m_analyze_in_reply\u001b[0;34m(self, messages, sender, config)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# Delegate to the analysis method.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"content\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"content\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0manalyze_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_to_analyze\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manalysis_instructions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogen/agentchat/contrib/text_analyzer_agent.py\u001b[0m in \u001b[0;36manalyze_text\u001b[0;34m(self, text_to_analyze, analysis_instructions)\u001b[0m\n\u001b[1;32m     69\u001b[0m         )  # Repeat the instructions.\n\u001b[1;32m     70\u001b[0m         \u001b[0;31m# Generate and return the analysis string.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_oai_reply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmsg_text\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogen/agentchat/conversable_agent.py\u001b[0m in \u001b[0;36mgenerate_oai_reply\u001b[0;34m(self, messages, sender, config)\u001b[0m\n\u001b[1;32m   1285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmessages\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m             \u001b[0mmessages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_oai_messages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msender\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1287\u001b[0;31m         extracted_response = self._generate_oai_reply_from_client(\n\u001b[0m\u001b[1;32m   1288\u001b[0m             \u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_oai_system_message\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1289\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogen/agentchat/conversable_agent.py\u001b[0m in \u001b[0;36m_generate_oai_reply_from_client\u001b[0;34m(self, llm_client, messages, cache)\u001b[0m\n\u001b[1;32m   1304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m         \u001b[0;31m# TODO: #1143 handle token limit exceeded error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m         response = llm_client.create(\n\u001b[0m\u001b[1;32m   1307\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"context\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m             \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_messages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogen/oai/client.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, **config)\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m                 \u001b[0mrequest_ts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_current_ts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mAPITimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"config {i} timed out\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogen/oai/client.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stream\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompletions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeout\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mNotGiven\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 581\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1230\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m         )\n\u001b[0;32m-> 1232\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    919\u001b[0m         \u001b[0mstream_cls\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_StreamT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m     ) -> ResponseT | _StreamT:\n\u001b[0;32m--> 921\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    922\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m             response = self._client.send(\n\u001b[0m\u001b[1;32m    951\u001b[0m                 \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m                 \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_stream_response_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0mauth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_request_auth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         response = self._send_handling_auth(\n\u001b[0m\u001b[1;32m    915\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m                 response = self._send_handling_redirects(\n\u001b[0m\u001b[1;32m    943\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m                     \u001b[0mfollow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_redirects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    977\u001b[0m                 \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_single_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_hooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"response\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1015\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSyncByteStream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    231\u001b[0m         )\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_httpcore_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_connections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;31m# Return the response. Note that in this case we still have to manage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                     \u001b[0;31m# Send the request on the assigned connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                     response = connection.handle_request(\n\u001b[0m\u001b[1;32m    197\u001b[0m                         \u001b[0mpool_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/connection.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNetworkStream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"response_closed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;31m# Sending the request...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    111\u001b[0m                     \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtrailing_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                 ) = self._receive_response_headers(**kwargs)\n\u001b[0m\u001b[1;32m    114\u001b[0m                 trace.return_value = (\n\u001b[1;32m    115\u001b[0m                     \u001b[0mhttp_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_receive_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEED_DATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                 data = self._network_stream.read(\n\u001b[0m\u001b[1;32m    225\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD_NUM_BYTES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_backends/sync.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1286\u001b[0m                     \u001b[0;34m\"non-zero flags not allowed in calls to recv() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m                     self.__class__)\n\u001b[0;32m-> 1288\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1289\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1159\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# useful info stored in vector store now\n",
        "with Cache.disk() as cache:\n",
        "  user_proxy.initiate_chat(\n",
        "      assistant,\n",
        "      question=\"Who is the current prime minister of germany?\",\n",
        "      max_turns=4,\n",
        "      message=react_prompt_message\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88ujLZxr0wjt",
        "outputId": "91100b36-6322-4de5-c2e0-e5a16fcd38a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user_proxy (to Assistant):\n",
            "\n",
            "\n",
            "Answer the following questions as best you can. You have access to tools provided.\n",
            "\n",
            "Use the following format:\n",
            "\n",
            "Question: the input question you must answer\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take\n",
            "Action Input: the input to the action\n",
            "Observation: the result of the action\n",
            "... (this process can repeat multiple times)\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "\n",
            "Begin!\n",
            "Question: What is the result of super bowl 2024?\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Assistant (to user_proxy):\n",
            "\n",
            "Question: What is the result of super bowl 2024?\n",
            "Thought: Based on the information provided, the Kansas City Chiefs won Super Bowl 2024.\n",
            "Final Answer: The Kansas City Chiefs won Super Bowl 2024.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "user_proxy (to Assistant):\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Assistant (to user_proxy):\n",
            "\n",
            "TERMINATE\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from autogen.agentchat.contrib.capabilities.teachability import MemoStore\n",
        "\n",
        "# memo_store = MemoStore(verbosity=0, reset=False, path_to_db_dir='./teachability_db')\n",
        "# memo_store.list_memos()"
      ],
      "metadata": {
        "id": "74RoJWnA7tqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retrieval Augmented Generation (RAG)"
      ],
      "metadata": {
        "id": "YN5CcbUnAjr9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyautogen chromadb sentence_transformers markdownify pypdf -q --progress-bar off"
      ],
      "metadata": {
        "id": "L6VNRAc8E4HS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "from google.colab import userdata\n",
        "from autogen import Cache\n",
        "\n",
        "from autogen import ConversableAgent\n",
        "from autogen.agentchat.contrib.retrieve_assistant_agent import RetrieveAssistantAgent\n",
        "from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent\n",
        "\n",
        "\n",
        "llm_config = {\n",
        "    \"model\": \"gpt-3.5-turbo\",\n",
        "    \"api_key\": userdata.get(\"OPENAI_API_KEY\"),\n",
        "    \"temperature\": 0.7\n",
        "}"
      ],
      "metadata": {
        "id": "Zqy4dxIbslR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_config = {\n",
        "    \"task\": \"qa\",\n",
        "    \"model\": llm_config[\"model\"],\n",
        "    \"client\": chromadb.PersistentClient(path=\"/tmp/chromadb\"),\n",
        "    \"embedding_model\": \"all-mpnet-base-v2\",\n",
        "    \"docs_path\": [\n",
        "        \"https://raw.githubusercontent.com/Azure-Samples/azure-search-sample-data/887f029a4f5b5fd30eaba844a1168141556b1c02/nasa-e-book/earth-txt-10/page-11.txt\",\n",
        "        \"https://raw.githubusercontent.com/Azure-Samples/azure-search-sample-data/887f029a4f5b5fd30eaba844a1168141556b1c02/nasa-e-book/earth-txt-10/page-13.txt\",\n",
        "        \"https://raw.githubusercontent.com/Azure-Samples/azure-search-sample-data/887f029a4f5b5fd30eaba844a1168141556b1c02/nasa-e-book/earth-txt-10/page-15.txt\",\n",
        "        \"https://raw.githubusercontent.com/Azure-Samples/azure-search-sample-data/887f029a4f5b5fd30eaba844a1168141556b1c02/nasa-e-book/earth-txt-10/page-17.txt\",\n",
        "        \"https://raw.githubusercontent.com/Azure-Samples/azure-search-sample-data/887f029a4f5b5fd30eaba844a1168141556b1c02/nasa-e-book/earth-txt-10/page-19.txt\",\n",
        "        \"https://raw.githubusercontent.com/Azure-Samples/azure-search-sample-data/887f029a4f5b5fd30eaba844a1168141556b1c02/nasa-e-book/earth-txt-10/page-21.txt\",\n",
        "        \"https://raw.githubusercontent.com/Azure-Samples/azure-search-sample-data/887f029a4f5b5fd30eaba844a1168141556b1c02/nasa-e-book/earth-txt-10/page-23.txt\",\n",
        "\n",
        "    ]\n",
        "}\n",
        "\n",
        "rag_proxy_agent = RetrieveUserProxyAgent(\n",
        "    name=\"rag_proxy_agent\",\n",
        "    human_input_mode=\"NEVER\",\n",
        "    retrieve_config=retriever_config,\n",
        "    code_execution_config=False,  # set to False if you don't want to execute any code\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369,
          "referenced_widgets": [
            "36a684a9ff1043188f27ebf1fe8c02ce",
            "d67865d2a22b48ed8dba7fb8dc9c227f",
            "7b2ddf03740b4287939e05c1390d7907",
            "aec4e8e1609e4f258e8a86cbbeb335fa",
            "da0109c535b8479b95507e2037af5eec",
            "e9c5bbc2757d4134ae1e5c21ef9aa8d7",
            "d5e8f4a2f8064268be11558d082a58cc",
            "61a6dbccd2674b11a07eae4f56d59ca9",
            "6317b67c11e6413e90cf1fffad7d4742",
            "0d3184a9e20c410aabf6a3c3b6335213",
            "81530a27b8ae4ce0a80308da3408f52a",
            "dad4bd44dba34e5f9666807b8e0fcb30",
            "d5c0e4b307f54904b54a92aae97843eb",
            "1b463d89db3e4efa8819caaa73c7636a",
            "de7d8e2c66e74b33a15ff43df15de2c9",
            "65c8dd29150748958a838aaad4df0b8c",
            "e41b76eebd4043fbb19365fcc37ad718",
            "d2fc3cb5435446b9acfbd246b12a2921",
            "29a62c55a62243d98eb7c0692ccaba33",
            "eea401248dc747dcb5d34169b04b0106",
            "db7cf0cfb22a4f2c9747cffe2f7d42a6",
            "bf4ad211aa5143be833db8d2a89ded28",
            "f5ae21441709449a9d3bb8af7d98631b",
            "ec16c49f207f41659fad9bdeae772db4",
            "3277b21396aa40da898b8d8b8f0f65a7",
            "429394a63e3644cdbdce8bbd8eeed7b7",
            "7af8c9379557460f84dc97ce184b0a95",
            "d089d3c40a2c44cea1b01898defa63f3",
            "7c5467ec5f984086a4ddc2326b4a7dd4",
            "7bdfeaab921d465285e5ecff3a9da680",
            "db5b1e9afd4143419515655e4570aece",
            "a1d7bef49a67463d81f0b513b744600d",
            "a4b624a4361a4b87bba5700807051d27",
            "dc4838e614a743168e0bf75a4e591dcb",
            "e5cdc72421604a3081c2b836baa74cab",
            "e638728a562a4e0283d7377dc94b7a1f",
            "1e4aa2dc416d4ab0b0cc39b184d3bf94",
            "f857da686fb44988b1f36052bea0d1a0",
            "12ddd572e13b42e6afddf85d765765d6",
            "3172a6e365864bd69529116912565bdb",
            "f73c9c23c4a34799933291f914981a6d",
            "67bdea1bef8141cc98f9b8e3d564e21d",
            "47d160388ffb453497b37d2bb8585b6f",
            "c54b38efb9eb4b6f80b8872761076ce5",
            "01060978bae6443a8e0ab4b6a7919e84",
            "d0e5e1bf13df4d56a152193fc9cfc5b1",
            "2effcca1d14d4e4aba8067fc4be51c22",
            "166e0a1839e74ecf96da83b91b41f6cc",
            "3e89cfe0e6d246c0b753829f205f24bc",
            "e3b55714551b42a49799fdc411b9695c",
            "f88f0dacb088450299f01d455cbf3f84",
            "9236adc5dfbb481c8bb509d00ab8c583",
            "f0a0c3c672e241b5af79ee17c15fb670",
            "99ba75fc30b24e23adc6d591768b77e0",
            "4bc52c89b24c44959689705f3cae4bcb",
            "07f8511b70a641d6bc5516456e0aae73",
            "a363b24baa194f27b576a1b296990568",
            "6d4cf1278cff4a1dbd6c01536fa48449",
            "629b12c7534649f1ad5facaeee3b0e35",
            "c534d53be5ea4031b02c55f91ecbe482",
            "7674459bbcc3481c85fec003cd1c2012",
            "310a4b7a64374d50b25f36704d84c85b",
            "837cd0c5e51146f9abf74e805e46c321",
            "5803bd7c21e34bedb573147f3a4ba03e",
            "5ccc3a2a92b14609b97a54590a49f52e",
            "e372cad798684087a13f2099a8d961aa",
            "c7079d414b9448bca43811f8781db78a",
            "42944b7cccf54743a2c54f9f5b71eb9e",
            "59cedf1233694473b1c86a00153beeac",
            "aa3303ee1f5e437c92559868f14849bc",
            "624b45ac25544fd0bf6dd0ef98eda520",
            "93a1c39416cf49cda347118a0729ae23",
            "b9793d5bd60441e0ab47834114754e7a",
            "33c027289ec1437c8e00c2282f682bea",
            "d50ea40c19f44ba1a9d6678320cc023c",
            "47cf7475f9c94367b4c4839f9a0dccdf",
            "27520c8a56cf4199b4d8003d015e67f7",
            "7388277f52e74427ba614a8563436f0c",
            "1eaeeeee2455478d95b222c18ac8196f",
            "4fafb13a492d457f8964fadc19131ca0",
            "2975b3a13fcd4a2cb3bb0d5a9f4e8978",
            "1b725c14c6f349a28b520757c631b3aa",
            "a2c3df00d1fe44c1bb5e19684b2d55f4",
            "033447a2eb1c4e41bcdec016543ea9bd",
            "f89046bde25b47768cfd1213906acd50",
            "6194a841279e40a6b7c73c3180c8390b",
            "16aeeed6554b40f49108bc8d77d1a36a",
            "ede286d49157435e833d32480d37a878",
            "a741701c79964e8f81a8fdea41b07d8b",
            "e81f12f2e7fe423f85acdf5eff9e9a44",
            "6a8f324c6f644e8d891985d67df63c91",
            "b54469c3ff824b759bfa992cd3a2855c",
            "c835aacb289f46f1bbbf35215f901e91",
            "a80a06bd54124c2ab97eeef5b9db69fc",
            "03039f1670eb49ef828cd4a0a8a762e5",
            "59dd932ccf314429a7bb9bea583ae0ac",
            "e68a087241e4467eb8c517036061c5aa",
            "e2e3a4d27a1d4939aa3f2281efdecb7d",
            "28cc6676acf04c088181b1697a5e3087",
            "3458d93337574d0295661433752b9688",
            "ff8df50e84d349d9bafc7a81dd28ab79",
            "7136cd8e06aa498492cb53668e163f8d",
            "aa373a29b1194b44842ce5985ebb1fe2",
            "04ea2508f1774a04a8962f5ade60fd84",
            "a1d4f2cd804c406fb52a34728c3d6724",
            "9cf5e14d05404efd9ab69852fa30c149",
            "8940221611d9412494987a64cc351fa5",
            "1ac943615e444bdeaab6eea5f65f1146",
            "3210d19ca0d946299f6894739cc6f883",
            "b66bd7f85c9942dcbbea281b9fe281ba",
            "32ab2267fade4b84838bf06045254895",
            "b0c7049fb0054e43960f1fa7a36d14b4",
            "809e3d796a1642ed9f205d1baaa2868f",
            "d1d24dab07c74ffd82fd2d6346360232",
            "c88e92a0b1ec4ad388b0671181013be5",
            "f43fd066b0754136913cc75f91ad9af0",
            "3d92ec2702ed48a0a5aeafb197b723db",
            "afbe21d915e946768f95fb001171dc6f",
            "d8f075b0fc784355924fe2b68441610b",
            "41e402956d984167895d135372caece3",
            "9ac6143a61c74b09b5713fac08edf9a1"
          ]
        },
        "id": "4rWF8iMYsmSZ",
        "outputId": "011d7984-d675-4e59-d6b2-5b5b2b5072f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36a684a9ff1043188f27ebf1fe8c02ce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dad4bd44dba34e5f9666807b8e0fcb30"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f5ae21441709449a9d3bb8af7d98631b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dc4838e614a743168e0bf75a4e591dcb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "01060978bae6443a8e0ab4b6a7919e84"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "07f8511b70a641d6bc5516456e0aae73"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c7079d414b9448bca43811f8781db78a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7388277f52e74427ba614a8563436f0c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a741701c79964e8f81a8fdea41b07d8b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3458d93337574d0295661433752b9688"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "32ab2267fade4b84838bf06045254895"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rag_assistant = RetrieveAssistantAgent(\n",
        "    name=\"rag_assistant\",\n",
        "    system_message=\"You are a helpful AI assistant.\",\n",
        "    llm_config={\n",
        "        \"timeout\": 600,\n",
        "        \"config_list\": [llm_config],\n",
        "    },\n",
        ")"
      ],
      "metadata": {
        "id": "-tl55qqzsn60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What causes the colorful ring-like phenomenon over the Pacific Ocean\"\n",
        "\n",
        "with Cache.disk() as cache:\n",
        "  rag_proxy_agent.initiate_chat(\n",
        "      rag_assistant,\n",
        "      problem=query,\n",
        "      n_results=2,\n",
        "      message=rag_proxy_agent.message_generator,\n",
        "      max_turns=5\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNtl4kBnsn4u",
        "outputId": "a3ee1ec9-5f2b-4072-d6c1-8ae98425eca9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trying to create collection.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-04-27 13:17:23,249 - autogen.agentchat.contrib.retrieve_user_proxy_agent - INFO - Found 7 chunks.\n",
            "2024-04-27 13:17:23,255 - autogen.agentchat.contrib.vectordb.chromadb - INFO - No content embedding is provided. Will use the VectorDB's embedding function to generate the content embedding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VectorDB returns doc_ids:  [['f6368edd', 'e7c488a3']]\n",
            "Adding content of doc f6368edd to context.\n",
            "Adding content of doc e7c488a3 to context.\n",
            "rag_proxy_agent (to rag_assistant):\n",
            "\n",
            "You're a retrieve augmented chatbot. You answer user's questions based on your own knowledge and the\n",
            "context provided by the user.\n",
            "If you can't answer the question with or without the current context, you should reply exactly `UPDATE CONTEXT`.\n",
            "You must give as short an answer as possible.\n",
            "\n",
            "User's question is: What causes the colorful ring-like phenomenon over the Pacific Ocean\n",
            "\n",
            "Context is: A Glorious View\tPacific Ocean\n",
            "A layer of stratocumulus clouds over the Pacific Ocean serves as the backdrop for this rainbow-like phenomenon known as a glory. \n",
            "Glories form when water droplets within clouds scatter sunlight back toward a source of illumination (in this case, the Sun). \n",
            "Although glories may look similar to rainbows, the way light is scattered to produce them is different. Rainbows are formed by refraction and reflection; glories are formed by backward diffraction. From the ground or from an airplane, glories appear as circular rings of color. In this image, however, the glory is stretched vertically because of how the imager scans the surface in swaths.\n",
            "Note, too, the swirling von Krmn vortices visible to the right of the glory. The alternating rows of vortices form as air masses run into an obstaclethe island of Guadalupeand form a wake behind it.\n",
            "\n",
            "10\n",
            "A Trio of Plumes\t\n",
            "South Atlantic Ocean\n",
            "The uninhabited South Sandwich Islands include several active stratovolcanoes. Due to their remote location, these volcanoes  are some of the least studied in the world, though satellites often catch them erupting. \n",
            "The combination of clouds and ice at these latitudes can make it difficult to see plumes of volcanic ash in natural-color imagery. But using portions of the electromagnetic spectrum that are typically invisible to the naked eye (such as infrared) enables satellites to distinguish ice from ash and clouds. The Aqua satellite captured this false-color image in September 2016. Note the three bright white plumes running down the middle third of the page; they are warmer and brighter in infrared than the cooler ice clouds (teal) around them.\n",
            "Researchers have learned that even small eruptions like this can affect cloud cover and weather. The tiny solid and liquid particles  in the plume (aerosols) act as seeds for the formation of cloud droplets.\n",
            "\n",
            "6\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "rag_assistant (to rag_proxy_agent):\n",
            "\n",
            "Glories form when water droplets within clouds scatter sunlight back toward a source of illumination, creating circular rings of color.\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}