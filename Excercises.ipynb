{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "T3tA5_d4iPsl",
        "rOWfMC48iWMx",
        "QXYTX5zClryt",
        "MbhVVYEjaWwY",
        "-xfWsZeDsx41",
        "H1R63d4f34dT"
      ],
      "authorship_tag": "ABX9TyOia/HfULZ1VmeN7sAdLJO5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shah-zeb-naveed/autogen-udemy-course/blob/main/Excercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALvzHEr6tSu2",
        "outputId": "4b8a9a88-66e0-49a8-836b-f0664ee19e01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.1/257.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.6/147.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.7/296.7 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.9/309.9 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "pip install pyautogen -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agents"
      ],
      "metadata": {
        "id": "T3tA5_d4iPsl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from autogen import ConversableAgent\n",
        "\n",
        "llm_config = {\n",
        "    \"model\": \"gpt-3.5-turbo\",\n",
        "    \"api_key\": userdata.get(\"OPENAI_API_KEY\"),\n",
        "    \"temperature\": 0.7,\n",
        "    \"max_tokens\": 10,\n",
        "}\n",
        "\n",
        "audience = ConversableAgent(\n",
        "    name = \"audience\",\n",
        "    max_consecutive_auto_reply = 2,\n",
        "    is_termination_msg = lambda msg: 'TERMINATE' in msg[\"content\"].upper(),\n",
        "    llm_config = llm_config,\n",
        "    system_message = 'You are a member of the audience of a comedy show that is hard to impress.'\n",
        ")\n",
        "\n",
        "comedian = ConversableAgent(\n",
        "    name = \"comedian\",\n",
        "    max_consecutive_auto_reply = 2,\n",
        "    llm_config = llm_config,\n",
        "    system_message = 'You are a member of the audience of a comedy show that is hard to impress.'\n",
        ")\n",
        "\n",
        "# terminate a chat\n",
        "\n",
        "comedian.initiate_chat(\n",
        "    audience,\n",
        "    message=\"Welcome to my standup comedy show! Are you ready for a night full of laughter?\",\n",
        "    max_turns = 2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BexHW23ldJqR",
        "outputId": "11a48cb7-6136-4157-9a00-026974cd55da"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "comedian (to audience):\n",
            "\n",
            "Welcome to my standup comedy show! Are you ready for a night full of laughter?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "audience (to comedian):\n",
            "\n",
            "We'll see about that! Impress us with your\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "comedian (to audience):\n",
            "\n",
            "Challenge accepted! Let me get started with some jokes\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "audience (to comedian):\n",
            "\n",
            "Go for it! We're all ears.\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatResult(chat_id=None, chat_history=[{'content': 'Welcome to my standup comedy show! Are you ready for a night full of laughter?', 'role': 'assistant'}, {'content': \"We'll see about that! Impress us with your\", 'role': 'user'}, {'content': 'Challenge accepted! Let me get started with some jokes', 'role': 'assistant'}, {'content': \"Go for it! We're all ears.\", 'role': 'user'}], summary=\"Go for it! We're all ears.\", cost={'usage_including_cached_inference': {'total_cost': 0.0001335, 'gpt-3.5-turbo-0125': {'cost': 0.0001335, 'prompt_tokens': 180, 'completion_tokens': 29, 'total_tokens': 209}}, 'usage_excluding_cached_inference': {'total_cost': 0.0001335, 'gpt-3.5-turbo-0125': {'cost': 0.0001335, 'prompt_tokens': 180, 'completion_tokens': 29, 'total_tokens': 209}}}, human_input=[])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Human-in-the-loop"
      ],
      "metadata": {
        "id": "rOWfMC48iWMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from autogen import ConversableAgent\n",
        "\n",
        "llm_config = {\n",
        "    \"model\": \"gpt-3.5-turbo\",\n",
        "    \"api_key\": userdata.get(\"OPENAI_API_KEY\"),\n",
        "    \"temperature\": 0.7\n",
        "}\n",
        "\n",
        "agent_guesser = ConversableAgent(\n",
        "    name=\"agent_guesser\",\n",
        "    system_message=\"\"\"Let's play a game. I have a person in mind, and you have to guess it.\n",
        "    I'll respond with 'yes' or 'no' with a hint.\n",
        "    You have 3 tries to guess the person's name. Don't ask for hints just make best use of information you already have received.\n",
        "    Go ahead and start guessing!\"\"\",\n",
        "    llm_config={\"config_list\": [llm_config]},\n",
        "    human_input_mode=\"NEVER\", # default\n",
        ")\n",
        "\n",
        "agent_thinker = ConversableAgent(\n",
        "    \"agent_thinker\",\n",
        "    system_message=\"\"\"Let's play a game. Think of a famous personality, and I'll try to guess their name on every turn.\n",
        "    Respond with 'yes' or 'no' with a hint. I have max 3 tries. Let's get started!\"\"\",\n",
        "    llm_config={\"config_list\": [llm_config]},\n",
        "    max_consecutive_auto_reply=1,  # maximum number of consecutive auto-replies before asking for human input\n",
        "    is_termination_msg=lambda msg: \"correct\" or \"right\" in msg[\"content\"].lower(),\n",
        "    human_input_mode=\"TERMINATE\",  # ask for human input until the game is terminated\n",
        ")\n",
        "\n",
        "result = agent_thinker.initiate_chat(\n",
        "    agent_guesser,\n",
        "    message=\"Let's start. I have someone in mind.\",\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uh6jgvpdAf-",
        "outputId": "307e0096-2bff-4575-f6a6-b7d4692531e3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "agent_thinker (to agent_guesser):\n",
            "\n",
            "Let's start. I have someone in mind.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "agent_guesser (to agent_thinker):\n",
            "\n",
            "Great! Is the person you have in mind a famous actor or actress?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Please give feedback to agent_guesser. Press enter or type 'exit' to stop the conversation: no\n",
            "agent_thinker (to agent_guesser):\n",
            "\n",
            "no\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "agent_guesser (to agent_thinker):\n",
            "\n",
            "Is the person you have in mind a musician?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Please give feedback to agent_guesser. Press enter or type 'exit' to stop the conversation: yes\n",
            "agent_thinker (to agent_guesser):\n",
            "\n",
            "yes\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "agent_guesser (to agent_thinker):\n",
            "\n",
            "Is the person you have in mind a male musician?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Please give feedback to agent_guesser. Press enter or type 'exit' to stop the conversation: yes\n",
            "agent_thinker (to agent_guesser):\n",
            "\n",
            "yes\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "agent_guesser (to agent_thinker):\n",
            "\n",
            "Is the person you have in mind a singer?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Please give feedback to agent_guesser. Press enter or type 'exit' to stop the conversation: yes\n",
            "agent_thinker (to agent_guesser):\n",
            "\n",
            "yes\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "agent_guesser (to agent_thinker):\n",
            "\n",
            "Is the person you have in mind known for their performances in the pop genre?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Please give feedback to agent_guesser. Press enter or type 'exit' to stop the conversation: exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code Executors"
      ],
      "metadata": {
        "id": "QXYTX5zClryt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tempfile\n",
        "from autogen import ConversableAgent\n",
        "from autogen.coding import LocalCommandLineCodeExecutor\n",
        "\n",
        "#temp_dir = tempfile.TemporaryDirectory()\n",
        "\n",
        "executor = LocalCommandLineCodeExecutor(\n",
        "    timeout=10,\n",
        "    work_dir='code/'\n",
        ")\n",
        "\n",
        "code_executor_agent = ConversableAgent(\n",
        "    name=\"code_executor_agent\",\n",
        "    llm_config=False,\n",
        "    code_execution_config={\"executor\": executor},\n",
        "    human_input_mode=\"NEVER\",\n",
        ")\n",
        "\n",
        "message_with_code_block = \"\"\"\n",
        "The code block is below:\n",
        "```python\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a DataFrame with sample data\n",
        "data = pd.DataFrame({\n",
        "    'x': np.arange(10),\n",
        "    'y': np.random.randint(0, 10, 10)\n",
        "})\n",
        "\n",
        "# Plot the line plot\n",
        "plt.plot(data['x'], data['y'])\n",
        "plt.xlabel('X-axis')\n",
        "plt.ylabel('Y-axis')\n",
        "plt.title('Line Plot')\n",
        "plt.savefig('lineplot.png')\n",
        "plt.show()\n",
        "print('Line plot saved to lineplot.png')\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "reply = code_executor_agent.generate_reply(messages=[{\"role\": \"user\", \"content\": message_with_code_block}])\n",
        "print(reply)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwHPAVyjlrj3",
        "outputId": "9bea6d99-bb02-4350-905e-ad2ebda3527b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>>>>>>> EXECUTING CODE BLOCK (inferred language is python)...\n",
            "exitcode: 0 (execution succeeded)\n",
            "Code output: Figure(640x480)\n",
            "Line plot saved to lineplot.png\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "code_assistant_system_message = \"\"\"You are a helpful AI assistant.\n",
        "Solve tasks using your coding and language skills.\n",
        "In the following cases, suggest python code (in a python coding block) or shell script (in a sh coding block) for the user to execute.\n",
        "1. When you need to collect info, use the code to output the info you need, for example, browse or search the web, download/read a file, print the content of a webpage or a file, get the current date/time, check the operating system. After sufficient info is printed and the task is ready to be solved based on your language skill, you can solve the task by yourself.\n",
        "2. When you need to perform some task with code, use the code to perform the task and output the result. Finish the task smartly.\n",
        "Solve the task step by step if you need to. If a plan is not provided, explain your plan first. Be clear which step uses code, and which step uses your language skill.\n",
        "When using code, you must indicate the script type in the code block. The user cannot provide any other feedback or perform any other action beyond executing the code you suggest. The user can't modify your code. So do not suggest incomplete code which requires users to modify. Don't use a code block if it's not intended to be executed by the user.\n",
        "If you want the user to save the code in a file before executing it, put # filename: <filename> inside the code block as the first line. Don't include multiple code blocks in one response. Do not ask users to copy and paste the result. Instead, use 'print' function for the output when relevant. Check the execution result returned by the user.\n",
        "If the result indicates there is an error, fix the error and output the code again. Suggest the full code instead of partial code or code changes. If the error can't be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a different approach to try.\n",
        "When you find an answer, verify the answer carefully. Include verifiable evidence in your response if possible.\n",
        "Reply 'TERMINATE' in the end when everything is done.\n",
        "\"\"\"\n",
        "\n",
        "code_assistant_system_message = \"\"\"You are a helpful AI assistant.\n",
        "Solve tasks using your coding and language skills.\n",
        "In the following cases, suggest python code (in a python coding block) or shell script (in a sh coding block) for the user to execute.\n",
        "1. When you need to collect info, use the code to output the info you need, for example, browse or search the web, download/read a file, print the content of a webpage or a file, get the current date/time, check the operating system. After sufficient info is printed and the task is ready to be solved based on your language skill, you can solve the task by yourself.\n",
        "2. When you need to perform some task with code, use the code to perform the task and output the result. Finish the task smartly.\n",
        "When using code, you must indicate the script type in the code block.\n",
        "\"\"\"\n",
        "\n",
        "code_assistant_system_message = \"\"\"You are a helpful AI assistant.\n",
        "Solve tasks using your coding skills. Suggest python code (in a python coding block) or shell script (in a sh coding block) for the user to execute.\n",
        "\"\"\"\n",
        "\n",
        "code_assistant = ConversableAgent(\n",
        "    \"code_assistant\",\n",
        "    system_message=code_assistant_system_message,\n",
        "    llm_config={\"config_list\": [llm_config]},\n",
        "    code_execution_config=False,  # Turn off code execution for this agent.\n",
        ")"
      ],
      "metadata": {
        "id": "3xQyHoN_pVDr"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_result = code_executor_agent.initiate_chat(\n",
        "    code_assistant,\n",
        "    message=\"Write Python code to calculate 23rd prime number\",\n",
        "    max_turns=2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyUDalSAqI0D",
        "outputId": "f170f4d6-442e-47d7-e060-848f24bc357b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "code_executor_agent (to code_assistant):\n",
            "\n",
            "Write Python code to calculate 23rd prime number\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "code_assistant (to code_executor_agent):\n",
            "\n",
            "Here is the Python code to calculate the 23rd prime number:\n",
            "\n",
            "```python\n",
            "def is_prime(num):\n",
            "    if num < 2:\n",
            "        return False\n",
            "    for i in range(2, int(num**0.5) + 1):\n",
            "        if num % i == 0:\n",
            "            return False\n",
            "    return True\n",
            "\n",
            "def find_nth_prime(n):\n",
            "    prime_count = 0\n",
            "    num = 2\n",
            "    while True:\n",
            "        if is_prime(num):\n",
            "            prime_count += 1\n",
            "            if prime_count == n:\n",
            "                return num\n",
            "        num += 1\n",
            "\n",
            "n = 23\n",
            "result = find_nth_prime(n)\n",
            "print(f\"The {n}rd prime number is: {result}\")\n",
            "```\n",
            "\n",
            "You can run this code to find the 23rd prime number.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> EXECUTING CODE BLOCK (inferred language is python)...\n",
            "code_executor_agent (to code_assistant):\n",
            "\n",
            "exitcode: 0 (execution succeeded)\n",
            "Code output: The 23rd prime number is: 83\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "code_assistant (to code_executor_agent):\n",
            "\n",
            "The 23rd prime number is 83. The code executed successfully. If you have any more questions or need further assistance, feel free to ask!\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tools"
      ],
      "metadata": {
        "id": "MbhVVYEjaWwY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def scrape_wiki_main_page(url: str) -> str:\n",
        "    \"\"\"\n",
        "    Scrapes news content from wikipedia's main page.\n",
        "\n",
        "    Args:\n",
        "        url (str): The URL of the wikipedia page to scrape.\n",
        "\n",
        "    Returns:\n",
        "        str: The text content of the webpage.\n",
        "             Returns None if there is an error during the process.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        if response.status_code == 200:\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "            content = soup.get_text()\n",
        "            content = content[content.find(\"In the news\"):content.find(\"Ongoing\")]\n",
        "            return content\n",
        "\n",
        "        else:\n",
        "            print(\"Failed to retrieve webpage. Status code:\", response.status_code)\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(\"An error occurred:\", e)\n",
        "        return None"
      ],
      "metadata": {
        "id": "nWDySB3XaXrM"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from autogen import ConversableAgent\n",
        "\n",
        "# Let's first define the assistant agent that suggests tool calls.\n",
        "assistant = ConversableAgent(\n",
        "    name=\"assistant\",\n",
        "    system_message=\"\"\"You are a helpful AI news bot.\n",
        "    You can pull content from wikipedia's main page.\n",
        "    URL: https://en.wikipedia.org/wiki/Main_Page. Once pulled, share top 3 stories.\n",
        "    Return 'TERMINATE' when the task is done.\"\"\",\n",
        "    llm_config={\"config_list\": [llm_config]},\n",
        ")\n",
        "\n",
        "# The user proxy agent is used for interacting with the assistant agent\n",
        "# and executes tool calls.\n",
        "user_proxy = ConversableAgent(\n",
        "    name=\"user_proxy\",\n",
        "    llm_config=False,\n",
        "    is_termination_msg=lambda msg: msg.get(\"content\") is not None and \"TERMINATE\" in msg[\"content\"],\n",
        "    human_input_mode=\"NEVER\",\n",
        ")\n",
        "\n",
        "# Register the tool signature with the assistant agent.\n",
        "assistant.register_for_llm(\n",
        "    name=\"scrape_wiki_main_page\",\n",
        "    description=\"A tool for scraping today's news from wikipedia\"\n",
        ")(scrape_wiki_main_page)\n",
        "\n",
        "# Register the tool function with the user proxy agent.\n",
        "user_proxy.register_for_execution(\n",
        "    name=\"scrape_wiki_main_page\"\n",
        ")(scrape_wiki_main_page)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bCAVETOQabjq",
        "outputId": "aaba8a17-950d-4bff-e32d-fa41723837f0"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.scrape_wiki_main_page(url: str) -> str>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>scrape_wiki_main_page</b><br/>def scrape_wiki_main_page(url: str) -&gt; str</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/&lt;ipython-input-26-09f6216e708d&gt;</a>Scrapes news content from wikipedia&#x27;s main page.\n",
              "\n",
              "Args:\n",
              "    url (str): The URL of the wikipedia page to scrape.\n",
              "\n",
              "Returns:\n",
              "    str: The text content of the webpage.\n",
              "         Returns None if there is an error during the process.</pre></div>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from autogen import Cache\n",
        "\n",
        "with Cache.disk() as cache:\n",
        "  chat_result = user_proxy.initiate_chat(\n",
        "      assistant,\n",
        "      message=\"What's hot in today's news?\",\n",
        "      max_turns=5,\n",
        "      summary_method=\"reflection_with_llm\"\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ne63Xnr3abhD",
        "outputId": "18c2da5e-a3b8-4c5a-8ca2-e9a32433b34e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user_proxy (to assistant):\n",
            "\n",
            "What's hot in today's news?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "assistant (to user_proxy):\n",
            "\n",
            "***** Suggested tool call (call_CBNwQtXvdT3mauP7zPauOMpk): scrape_wiki_main_page *****\n",
            "Arguments: \n",
            "{\"url\":\"https://en.wikipedia.org/wiki/Main_Page\"}\n",
            "**************************************************************************************\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> EXECUTING FUNCTION scrape_wiki_main_page...\n",
            "user_proxy (to assistant):\n",
            "\n",
            "user_proxy (to assistant):\n",
            "\n",
            "***** Response from calling tool (call_CBNwQtXvdT3mauP7zPauOMpk) *****\n",
            "In the news\n",
            "\n",
            "\n",
            "Børsen in 2010\n",
            "\n",
            "The historic Børsen (pictured) in Copenhagen, Denmark, catches fire.\n",
            "In retaliation for an Israeli airstrike on the Iranian consulate in Damascus, Iran conducts missile and drone strikes against Israel.\n",
            "In the South Korean legislative election, the Democratic Party–led opposition alliance increases its majority in parliament.\n",
            "American football Hall of Fame running back, murder suspect and convicted criminal O. J. Simpson dies at the age of 76.\n",
            "Simon Harris becomes Taoiseach of Ireland after Leo Varadkar's resignation.\n",
            "\n",
            "\n",
            "**********************************************************************\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "assistant (to user_proxy):\n",
            "\n",
            "Here are the top 3 stories from today's news:\n",
            "1. The historic Børsen in Copenhagen, Denmark catches fire.\n",
            "2. Iran conducts missile and drone strikes against Israel in retaliation for an Israeli airstrike on the Iranian consulate in Damascus.\n",
            "3. In the South Korean legislative election, the Democratic Party–led opposition alliance increases its majority in parliament.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "user_proxy (to assistant):\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "assistant (to user_proxy):\n",
            "\n",
            "TERMINATE\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assistant.llm_config[\"tools\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3RurRG4fTjU",
        "outputId": "7b3c34e8-9f91-4d39-ad58-31c71f4e45b7"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'type': 'function',\n",
              "  'function': {'description': \"A tool for scraping today's news from wikipedia\",\n",
              "   'name': 'scrape_wiki_main_page',\n",
              "   'parameters': {'type': 'object',\n",
              "    'properties': {'url': {'type': 'string', 'description': 'url'}},\n",
              "    'required': ['url']}}}]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_result.summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "n1_FKz3kj0fs",
        "outputId": "17d58887-e7c7-4571-c38e-b0948d227aa9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The top news stories for today are the fire at Børsen in Copenhagen, Iran's retaliatory strikes against Israel, and the South Korean legislative election results.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ConversableAgent.DEFAULT_SUMMARY_PROMPT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qo6yGzHRnw4Z",
        "outputId": "1f270a5d-abf6-4942-d977-a1f01a48aa95"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarize the takeaway from the conversation. Do not add any introductory phrases.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_result.cost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXLEepBBn3vZ",
        "outputId": "3b02f602-b3e9-426b-ef89-a1ea42affb1c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'usage_including_cached_inference': {'total_cost': 0.00147,\n",
              "  'gpt-3.5-turbo-0125': {'cost': 0.00147,\n",
              "   'prompt_tokens': 2118,\n",
              "   'completion_tokens': 274,\n",
              "   'total_tokens': 2392}},\n",
              " 'usage_excluding_cached_inference': {'total_cost': 0.000735,\n",
              "  'gpt-3.5-turbo-0125': {'cost': 0.000735,\n",
              "   'prompt_tokens': 1059,\n",
              "   'completion_tokens': 137,\n",
              "   'total_tokens': 1196}}}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_result.human_input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5DfTocJoJT1",
        "outputId": "360ed0d6-f2f8-4cae-af0b-845eefb89b1f"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_result.chat_history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQEHsBUHn9oc",
        "outputId": "53e17df5-9771-4ef9-fb61-5d17f51708ca"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'content': \"What's hot in today's news?\", 'role': 'assistant'},\n",
              " {'tool_calls': [{'id': 'call_CBNwQtXvdT3mauP7zPauOMpk',\n",
              "    'function': {'arguments': '{\"url\":\"https://en.wikipedia.org/wiki/Main_Page\"}',\n",
              "     'name': 'scrape_wiki_main_page'},\n",
              "    'type': 'function'}],\n",
              "  'content': None,\n",
              "  'role': 'assistant'},\n",
              " {'content': \"In the news\\n\\n\\nBørsen in 2010\\n\\nThe historic Børsen (pictured) in Copenhagen, Denmark, catches fire.\\nIn retaliation for an Israeli airstrike on the Iranian consulate in Damascus, Iran conducts missile and drone strikes against Israel.\\nIn the South Korean legislative election, the Democratic Party–led opposition alliance increases its majority in parliament.\\nAmerican football Hall of Fame running back, murder suspect and convicted criminal O. J. Simpson dies at the age of 76.\\nSimon Harris becomes Taoiseach of Ireland after Leo Varadkar's resignation.\\n\\n\",\n",
              "  'tool_responses': [{'tool_call_id': 'call_CBNwQtXvdT3mauP7zPauOMpk',\n",
              "    'role': 'tool',\n",
              "    'content': \"In the news\\n\\n\\nBørsen in 2010\\n\\nThe historic Børsen (pictured) in Copenhagen, Denmark, catches fire.\\nIn retaliation for an Israeli airstrike on the Iranian consulate in Damascus, Iran conducts missile and drone strikes against Israel.\\nIn the South Korean legislative election, the Democratic Party–led opposition alliance increases its majority in parliament.\\nAmerican football Hall of Fame running back, murder suspect and convicted criminal O. J. Simpson dies at the age of 76.\\nSimon Harris becomes Taoiseach of Ireland after Leo Varadkar's resignation.\\n\\n\"}],\n",
              "  'role': 'tool'},\n",
              " {'content': \"Here are the top 3 stories from today's news:\\n1. The historic Børsen in Copenhagen, Denmark catches fire.\\n2. Iran conducts missile and drone strikes against Israel in retaliation for an Israeli airstrike on the Iranian consulate in Damascus.\\n3. In the South Korean legislative election, the Democratic Party–led opposition alliance increases its majority in parliament.\",\n",
              "  'role': 'user'},\n",
              " {'content': '', 'role': 'assistant'},\n",
              " {'content': 'TERMINATE', 'role': 'user'}]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sequential Chats"
      ],
      "metadata": {
        "id": "-xfWsZeDsx41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from autogen import ConversableAgent\n",
        "from google.colab import userdata\n",
        "\n",
        "llm_config = {\n",
        "    \"model\": \"gpt-3.5-turbo\",\n",
        "    \"api_key\": userdata.get(\"OPENAI_API_KEY\"),\n",
        "    \"temperature\": 0.7,\n",
        "    \"max_tokens\": 10\n",
        "}\n",
        "\n",
        "# Define the agents\n",
        "\n",
        "# The Adventurer Agent seeks advice from a Wizard on magical matters.\n",
        "adventurer_agent = ConversableAgent(\n",
        "    name=\"Adventurer_Agent\",\n",
        "    system_message=\"You are a worthy adventurous hero seeking advice from a Wizard on magical matters. Briefly communicate in less than 10 words.\",\n",
        "    llm_config={\"config_list\": [llm_config]},\n",
        "    human_input_mode=\"NEVER\",\n",
        ")\n",
        "\n",
        "# The Wizard Agent is an expert in magic and provides magical advice to the Adventurer.\n",
        "wizard_agent = ConversableAgent(\n",
        "    name=\"Wizard_Agent\",\n",
        "    system_message=\"You are a wise and powerful Wizard. You provide magical advice to the Adventurer on their quest. You know the passcode to the vault is Enigma.  Briefly communicate in less than 10 words.\",\n",
        "    llm_config={\"config_list\": [llm_config]},\n",
        "    human_input_mode=\"NEVER\",\n",
        ")\n",
        "\n",
        "# The Protector Agent guards the hidden gem and offers protection to the Adventurer.\n",
        "protector_agent = ConversableAgent(\n",
        "    name=\"Protector_Agent\",\n",
        "    system_message=\"You are the Guardian of the Hidden Gem, sworn to protect it from unworthy adventurers. The passcode to the vault is Enigma. If adventurer tells you the passcode, say 'Welcome!' otherwise say 'Incorrect Passcode'.  Briefly communicate in less than 10 words.\",\n",
        "    llm_config={\"config_list\": [llm_config]},\n",
        "    human_input_mode=\"NEVER\",\n",
        ")"
      ],
      "metadata": {
        "id": "OqptOmjtszJg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start a sequence of two-agent chats.\n",
        "# Each element in the list is a dictionary that specifies the arguments\n",
        "# for the initiate_chat method.\n",
        "chat_results = adventurer_agent.initiate_chats(\n",
        "    [\n",
        "        {\n",
        "            \"recipient\": wizard_agent,\n",
        "            \"message\": \"Help me get past the Guardian of the Hidden Gem in the secret vault.\",\n",
        "            \"max_turns\": 1,\n",
        "            \"summary_method\": \"reflection_with_llm\",\n",
        "        },\n",
        "        {\n",
        "            \"recipient\": protector_agent,\n",
        "            \"message\": \"Allow me to enter the secret vault!\",\n",
        "            \"max_turns\": 1\n",
        "        }\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtXvYPZruzHI",
        "outputId": "fd52e03e-fd9d-4b96-cd49-5849b83b7949"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "Adventurer_Agent (to Wizard_Agent):\n",
            "\n",
            "Help me get past the Guardian of the Hidden Gem in the secret vault.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Wizard_Agent (to Adventurer_Agent):\n",
            "\n",
            "Speak \"Enigma\" to access the hidden gem\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "Adventurer_Agent (to Protector_Agent):\n",
            "\n",
            "Allow me to enter the secret vault!\n",
            "Context: \n",
            "Speak \"Enigma\" to access the hidden gem\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Protector_Agent (to Adventurer_Agent):\n",
            "\n",
            "Welcome!\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_results[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48vvUnWI0OEO",
        "outputId": "1bbd8e77-a73b-49d5-9829-7fe02a59ca53"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatResult(chat_id=None, chat_history=[{'content': 'Help me get past the Guardian of the Hidden Gem in the secret vault.', 'role': 'assistant'}, {'content': 'Speak \"Enigma\" to access the hidden gem', 'role': 'user'}], summary='Speak \"Enigma\" to access the hidden gem', cost={'usage_including_cached_inference': {'total_cost': 9.25e-05, 'gpt-3.5-turbo-0125': {'cost': 9.25e-05, 'prompt_tokens': 125, 'completion_tokens': 20, 'total_tokens': 145}}, 'usage_excluding_cached_inference': {'total_cost': 4.2999999999999995e-05, 'gpt-3.5-turbo-0125': {'cost': 4.2999999999999995e-05, 'prompt_tokens': 56, 'completion_tokens': 10, 'total_tokens': 66}}}, human_input=[])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_results[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yD0VUBAL0OcZ",
        "outputId": "097b06d9-91d1-40b4-9ae4-6173dcec5662"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatResult(chat_id=None, chat_history=[{'content': 'Allow me to enter the secret vault!\\nContext: \\nSpeak \"Enigma\" to access the hidden gem', 'role': 'assistant'}, {'content': 'Welcome!', 'role': 'user'}], summary='Welcome!', cost={'usage_including_cached_inference': {'total_cost': 4.8e-05, 'gpt-3.5-turbo-0125': {'cost': 4.8e-05, 'prompt_tokens': 90, 'completion_tokens': 2, 'total_tokens': 92}}, 'usage_excluding_cached_inference': {'total_cost': 4.8e-05, 'gpt-3.5-turbo-0125': {'cost': 4.8e-05, 'prompt_tokens': 90, 'completion_tokens': 2, 'total_tokens': 92}}}, human_input=[])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nested Chat"
      ],
      "metadata": {
        "id": "fe7aWG3blXJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "poetry_agent = ConversableAgent(\n",
        "    name=\"Poet\",\n",
        "    system_message=\"You are an AI poet. Create only one stanza.\",\n",
        "    llm_config={\"config_list\": [llm_config]},\n",
        "    human_input_mode=\"NEVER\",\n",
        ")\n",
        "\n",
        "nested_chats = [\n",
        "    {\n",
        "        \"recipient\": wizard_agent,\n",
        "        \"max_turns\": 1,\n",
        "        \"summary_method\": \"reflection_with_llm\",\n",
        "        \"summary_prompt\": \"Concisely summarize the instructions given by wizard agent to communicate with protector agent.\",\n",
        "    },\n",
        "    {\n",
        "        \"recipient\": protector_agent,\n",
        "        \"max_turns\": 1,\n",
        "        \"message\": \"Allow me to enter the secret vault!\",\n",
        "        \"summary_method\": \"reflection_with_llm\",\n",
        "        \"summary_prompt\": \"Concisely summarize the adventure.\",\n",
        "    },\n",
        "    {\n",
        "        \"recipient\": poetry_agent,\n",
        "        \"max_turns\": 1,\n",
        "        \"message\": \"Write a poem on adventurer's expedition.\",\n",
        "        \"summary_method\": \"last_msg\",\n",
        "    },\n",
        "]\n",
        "\n",
        "adventurer_agent.register_nested_chats(\n",
        "    nested_chats,\n",
        "    # The trigger function is used to determine if the agent should start the nested chat\n",
        "    # given the sender agent.\n",
        "    # In this case, the arithmetic agent will not start the nested chats if the sender is\n",
        "    # from the nested chats' recipient to avoid recursive calls.\n",
        "    trigger=lambda sender: sender not in [wizard_agent, protector_agent, poetry_agent],\n",
        ")"
      ],
      "metadata": {
        "id": "g9DP00y8lbkw"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adventurer_agent.generate_reply(messages=[{'role' : 'user', 'content' : 'hi'}])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "MdQ0D7ezpzcp",
        "outputId": "119e608a-2720-498a-e41d-82847f59bd4b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Seek magical counsel, brave hero, how may I'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adventurer_agent.generate_reply(messages=[{'role' : 'assistant', 'content' : 'hi'}])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "pzuYYp71qsiE",
        "outputId": "0dfbe69a-943e-4e3f-f9ab-69d06fd277ff"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Seek wisdom, wield magic, embrace destiny.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adventurer_agent.chat_messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5UDIVDzpSO0",
        "outputId": "a417ea7c-0d08-458f-ae95-c03833a2e690"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(list, {})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adventurer_agent.last_message()"
      ],
      "metadata": {
        "id": "h2Zq12GNpUr0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_results = user_proxy.initiate_chat(adventurer_agent, max_turns=2)\n",
        "chat_results\n",
        "\n",
        "\n",
        "# user_proxy ignores the message and relies on input\n",
        "# input routed as is to the first recipient"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zw55TcSWr5-f",
        "outputId": "ebe06502-8934-4586-93da-beee53c3ccb9"
      },
      "execution_count": 37,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">Help me get past the Guardian of the Hidden Gem in the secret vault.\n",
            "user_proxy (to Adventurer_Agent):\n",
            "\n",
            "Help me get past the Guardian of the Hidden Gem in the secret vault.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "Adventurer_Agent (to Wizard_Agent):\n",
            "\n",
            "Help me get past the Guardian of the Hidden Gem in the secret vault.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Wizard_Agent (to Adventurer_Agent):\n",
            "\n",
            "Speak \"Enigma\" to pass the Guardian and\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "Adventurer_Agent (to Protector_Agent):\n",
            "\n",
            "Allow me to enter the secret vault!\n",
            "Context: \n",
            "To pass the Guardian of the Hidden Gem in the\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Protector_Agent (to Adventurer_Agent):\n",
            "\n",
            "Incorrect Passcode.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "Adventurer_Agent (to Poet):\n",
            "\n",
            "Write a poem on adventurer's expedition.\n",
            "Context: \n",
            "To pass the Guardian of the Hidden Gem in the\n",
            "Incorrect Passcode.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Poet (to Adventurer_Agent):\n",
            "\n",
            "Through perilous terrain and treacherous trials,\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Adventurer_Agent (to user_proxy):\n",
            "\n",
            "Through perilous terrain and treacherous trials,\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Provide feedback to Adventurer_Agent. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: exit\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatResult(chat_id=None, chat_history=[{'content': 'Help me get past the Guardian of the Hidden Gem in the secret vault.', 'role': 'assistant'}, {'content': 'Through perilous terrain and treacherous trials,\\n', 'role': 'user'}], summary='Through perilous terrain and treacherous trials,\\n', cost={'usage_including_cached_inference': {'total_cost': 0.00020050000000000002, 'gpt-3.5-turbo-0125': {'cost': 0.00020050000000000002, 'prompt_tokens': 224, 'completion_tokens': 59, 'total_tokens': 283}}, 'usage_excluding_cached_inference': {'total_cost': 0.0001675, 'gpt-3.5-turbo-0125': {'cost': 0.0001675, 'prompt_tokens': 188, 'completion_tokens': 49, 'total_tokens': 237}}}, human_input=['Help me get past the Guardian of the Hidden Gem in the secret vault.', 'exit'])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reply = adventurer_agent.generate_reply(\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Help me get past the Guardian of the Hidden Gem in the secret vault.\"}]\n",
        ")\n",
        "\n",
        "# same output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckqfEz7ilbgU",
        "outputId": "6ce35c57-bbff-442b-e2db-8498d6c06074"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "Adventurer_Agent (to Wizard_Agent):\n",
            "\n",
            "Help me get past the Guardian of the Hidden Gem in the secret vault.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Wizard_Agent (to Adventurer_Agent):\n",
            "\n",
            "Speak \"Enigma\" to pass the Guardian and\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "Adventurer_Agent (to Protector_Agent):\n",
            "\n",
            "Allow me to enter the secret vault!\n",
            "Context: \n",
            "To pass the Guardian of the Hidden Gem in the\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Protector_Agent (to Adventurer_Agent):\n",
            "\n",
            "Incorrect Passcode.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "Adventurer_Agent (to Poet):\n",
            "\n",
            "Write a poem on adventurer's expedition.\n",
            "Context: \n",
            "To pass the Guardian of the Hidden Gem in the\n",
            "Incorrect Passcode.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Poet (to Adventurer_Agent):\n",
            "\n",
            "Through perilous terrain and treacherous trials,\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reply = adventurer_agent.generate_reply(\n",
        "    messages=[{\"role\": \"assistant\", \"content\": \"Help me get past the Guardian of the Hidden Gem in the secret vault.\"}]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpnXIksllbeP",
        "outputId": "b8e83638-0618-4441-d54b-a3612b80fa06"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "Adventurer_Agent (to Wizard_Agent):\n",
            "\n",
            "Help me get past the Guardian of the Hidden Gem in the secret vault.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Wizard_Agent (to Adventurer_Agent):\n",
            "\n",
            "Speak \"Enigma\" to pass the Guardian and\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "Adventurer_Agent (to Protector_Agent):\n",
            "\n",
            "Allow me to enter the secret vault!\n",
            "Context: \n",
            "To pass the Guardian of the Hidden Gem in the\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Protector_Agent (to Adventurer_Agent):\n",
            "\n",
            "Incorrect Passcode.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "Adventurer_Agent (to Poet):\n",
            "\n",
            "Write a poem on adventurer's expedition.\n",
            "Context: \n",
            "To pass the Guardian of the Hidden Gem in the\n",
            "Incorrect Passcode.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Poet (to Adventurer_Agent):\n",
            "\n",
            "Through perilous terrain and treacherous trials,\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "8uWMtNujlbb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Impact of Role"
      ],
      "metadata": {
        "id": "9N76_15SzZpq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent = ConversableAgent(\n",
        "    \"chatbot\",\n",
        "    llm_config={\"config_list\": [llm_config]},\n",
        "    code_execution_config=False,  # Turn off code execution, by default it is off.\n",
        "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
        ")\n",
        "\n",
        "reply = agent.generate_reply(messages=[{\"content\": \"Tell me a joke.\", \"role\": \"user\"}])\n",
        "print(reply)\n",
        "\n",
        "reply = agent.generate_reply(messages=[{\"content\": \"Tell me a joke.\", \"role\": \"assistant\"}])\n",
        "print(reply)\n",
        "\n",
        "# role doesn't make a difference"
      ],
      "metadata": {
        "id": "KFEi6R9qzcHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Group Chat"
      ],
      "metadata": {
        "id": "H1R63d4f34dT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from autogen import GroupChat, GroupChatManager\n",
        "\n",
        "# Define the roles and their descriptions\n",
        "product_manager = ConversableAgent(\n",
        "    name=\"product_manager\",\n",
        "    system_message=\"You are an expert Product Manager working in a scrum team of an IT company. You like innovation and introducing new features as soon as possible.\",\n",
        "    llm_config={\"config_list\": [llm_config]},\n",
        "    human_input_mode=\"NEVER\",\n",
        "    description=\"Provide product requirements and priorities.\"\n",
        ")\n",
        "\n",
        "scrum_master = ConversableAgent(\n",
        "    name=\"scrum_master\",\n",
        "    system_message=\"You are a scrum master leading the 14-day sprints in an IT company. You provide technical leadership and make sure work is apporpirately planned.\",\n",
        "    llm_config={\"config_list\": [llm_config]},\n",
        "    human_input_mode=\"NEVER\",\n",
        "    description=\"Lead the sprint planning process.\"\n",
        ")\n",
        "\n",
        "software_engineer = ConversableAgent(\n",
        "    name=\"software_engineer\",\n",
        "    system_message=\"You are a senior software engineer in an IT company. You write software and technical documentation.\",\n",
        "    llm_config={\"config_list\": [llm_config]},\n",
        "    human_input_mode=\"NEVER\",\n",
        "    description=\"Provide insights on technical feasibility and effort estimation.\"\n",
        ")\n",
        "\n",
        "\n",
        "allowed_transitions = {\n",
        "    product_manager: [scrum_master],\n",
        "    scrum_master: [software_engineer, product_manager],\n",
        "    software_engineer: [scrum_master],\n",
        "\n",
        "}\n",
        "\n",
        "# Create a GroupChat object and provide the list of agents\n",
        "sprint_planning_chat = GroupChat(\n",
        "    agents=[product_manager, scrum_master, software_engineer],\n",
        "    messages=[],\n",
        "    max_round=5,  # Setting a maximum round for the conversation,\n",
        "    send_introductions=True,\n",
        "    allowed_or_disallowed_speaker_transitions=allowed_transitions,\n",
        "    speaker_transitions_type=\"allowed\",\n",
        ")\n",
        "\n",
        "# Create a GroupChatManager object and provide the GroupChat object as input\n",
        "sprint_planning_chat_manager = GroupChatManager(\n",
        "    groupchat=sprint_planning_chat,\n",
        "    llm_config={\"config_list\": [llm_config]},  # Assuming the use of GPT-4 model\n",
        ")\n",
        "\n",
        "# Initiate the chat with the product_manager as the starting speaker\n",
        "chat_result = product_manager.initiate_chat(\n",
        "    sprint_planning_chat_manager,\n",
        "    message=\"We have a request to create a portal to track employee HR requests. How do we go about it?\",\n",
        "    summary_method=\"reflection_with_llm\", # what's the point of this?\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFdhpahG358Z",
        "outputId": "35a51a6b-d351-41ff-fd91-2f941f419080"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "product_manager (to chat_manager):\n",
            "\n",
            "We have a request to create a web portal to track employee IT requests. How do we go about it?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "scrum_master (to chat_manager):\n",
            "\n",
            "As the scrum master, I will facilitate the\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "software_engineer (to chat_manager):\n",
            "\n",
            "process of sprint planning for this project. Let's\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "product_manager (to chat_manager):\n",
            "\n",
            "start by discussing the overall goal of the web portal\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "scrum_master (to chat_manager):\n",
            "\n",
            "Agreed. Let's define the goal of the\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_result.summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "Lr1eXp80652F",
        "outputId": "324024d4-a7a8-43de-c559-872b4f9a126f"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The team will define the overall goal of the web'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Speaker Selection"
      ],
      "metadata": {
        "id": "NcaK9jRUkB8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_speaker_selection(last_speaker, groupchat):\n",
        "    messages = groupchat.messages\n",
        "\n",
        "    if last_speaker is scrum_master:\n",
        "        return product_manager\n",
        "    elif last_speaker is software_engineer:\n",
        "        return scrum_master\n",
        "    elif last_speaker is product_manager:\n",
        "        return software_engineer\n",
        "\n",
        "    return None\n",
        "\n",
        "groupchat = autogen.GroupChat(\n",
        "    agents=[initializer, coder, executor, scientist],\n",
        "    messages=[],\n",
        "    max_round=20,\n",
        "    speaker_selection_method=state_transition,\n",
        ")\n",
        "\n",
        "sprint_planning_chat = GroupChat(\n",
        "    agents=[product_manager, scrum_master, software_engineer],\n",
        "    messages=[],\n",
        "    max_round=3,\n",
        "    send_introductions=True,\n",
        "    speaker_selection_method=state_transition,\n",
        ")\n",
        "\n",
        "sprint_planning_chat_manager = GroupChatManager(\n",
        "    groupchat=sprint_planning_chat,\n",
        "    llm_config={\"config_list\": [llm_config]},\n",
        ")\n",
        "\n",
        "# Initiate the chat\n",
        "chat_result = product_manager.initiate_chat(\n",
        "    sprint_planning_chat_manager,\n",
        "    message=\"We have a request to create a portal to track employee HR requests. How do we go about it?\",\n",
        "    summary_method=\"reflection_with_llm\", # what's the point of this?\n",
        ")\n"
      ],
      "metadata": {
        "id": "UR6cpXy467EI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}